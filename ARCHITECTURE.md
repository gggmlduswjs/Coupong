# ì¿ íŒ¡ ë„ì„œ íŒë§¤ ìë™í™” ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

## ğŸ“‹ ëª©ì°¨
1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
3. [ë””ë ‰í† ë¦¬ êµ¬ì¡°](#ë””ë ‰í† ë¦¬-êµ¬ì¡°)
4. [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ](#ë°ì´í„°ë² ì´ìŠ¤-ìŠ¤í‚¤ë§ˆ)
5. [ëª¨ë“ˆ ì„¤ê³„](#ëª¨ë“ˆ-ì„¤ê³„)
6. [ë°ì´í„° í”Œë¡œìš°](#ë°ì´í„°-í”Œë¡œìš°)
7. [API ì„¤ê³„](#api-ì„¤ê³„)
8. [ë°°í¬ ì „ëµ](#ë°°í¬-ì „ëµ)

---

## ì‹œìŠ¤í…œ ê°œìš”

### í•µì‹¬ ê¸°ëŠ¥
1. **í¬ë¡¤ë§ ì—”ì§„**: êµë³´ë¬¸ê³  ì‹ ê°„ êµì¬ ìë™ ìˆ˜ì§‘
2. **ìƒí’ˆ í”„ë¡œì„¸ì„œ**: ì¿ íŒ¡ ì—…ë¡œë“œìš© ë°ì´í„° ìë™ ìƒì„±
3. **ì—…ë¡œë“œ ì—”ì§„**: 5ê°œ ê³„ì • ìë™ ì—…ë¡œë“œ (CSV/Playwright)
4. **ë¶„ì„ ì—”ì§„**: íŒë§¤ ë¶€ì§„ ì›ì¸ ë¶„ì„ (ë…¸ì¶œ vs ì „í™˜)
5. **ëŒ€ì‹œë³´ë“œ**: ì—„ë§ˆìš© ê°„ë‹¨ UI (Streamlit)

### í•µì‹¬ ì œì•½
- ë„ì„œ ê°€ê²© ê³ ì •: ì •ê°€ Ã— 0.9
- ê³„ì • 5ê°œ ë™ì‹œ ìš´ì˜
- ì•½ê´€ ìœ„ë°˜ ìµœì†Œí™”
- ì‹¤ì œ ì‘ë™ í•„ìˆ˜

---

## ê¸°ìˆ  ìŠ¤íƒ

### Backend
```
- Python 3.11+
- FastAPI (REST API)
- SQLite â†’ PostgreSQL (ë‚˜ì¤‘ì— ë§ˆì´ê·¸ë ˆì´ì…˜)
- SQLAlchemy (ORM)
- Celery + Redis (ë¹„ë™ê¸° ì‘ì—…)
```

### í¬ë¡¤ë§/ìë™í™”
```
- Playwright (êµë³´ë¬¸ê³  í¬ë¡¤ë§, ì¿ íŒ¡ ì—…ë¡œë“œ)
- BeautifulSoup4 (HTML íŒŒì‹±)
- Pandas (ë°ì´í„° ì²˜ë¦¬)
```

### ëŒ€ì‹œë³´ë“œ
```
- Streamlit (ì—„ë§ˆìš© UI)
- Plotly (ì°¨íŠ¸)
```

### ì¸í”„ë¼
```
- Docker + Docker Compose
- Nginx (ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)
- GitHub Actions (CI/CD)
```

### ë³´ì•ˆ
```
- python-dotenv (í™˜ê²½ë³€ìˆ˜)
- cryptography (ê³„ì • ì •ë³´ ì•”í˜¸í™”)
```

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
coupang-auto/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ ARCHITECTURE.md (ì´ íŒŒì¼)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ config.py                  # ì„¤ì • ê´€ë¦¬
â”‚   â”œâ”€â”€ database.py                # DB ì—°ê²°
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                    # SQLAlchemy ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ account.py             # ê³„ì • ì •ë³´
â”‚   â”‚   â”œâ”€â”€ product.py             # ìƒí’ˆ ë§ˆìŠ¤í„°
â”‚   â”‚   â”œâ”€â”€ listing.py             # ê³„ì •ë³„ ìƒí’ˆ ë“±ë¡ í˜„í™©
â”‚   â”‚   â”œâ”€â”€ sales.py               # íŒë§¤ ë°ì´í„°
â”‚   â”‚   â””â”€â”€ task.py                # ì‘ì—… ë¡œê·¸
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                   # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ product.py
â”‚   â”‚   â”œâ”€â”€ listing.py
â”‚   â”‚   â””â”€â”€ sales.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                  # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ crawler_service.py     # í¬ë¡¤ë§ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ product_service.py     # ìƒí’ˆ ìƒì„± ë¡œì§
â”‚   â”‚   â”œâ”€â”€ uploader_service.py    # ì—…ë¡œë“œ ë¡œì§
â”‚   â”‚   â””â”€â”€ analyzer_service.py    # ë¶„ì„ ë¡œì§
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                     # Celery ë¹„ë™ê¸° ì‘ì—…
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ crawl_tasks.py
â”‚   â”‚   â”œâ”€â”€ upload_tasks.py
â”‚   â”‚   â””â”€â”€ analyze_tasks.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                       # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ products.py
â”‚   â”‚   â”œâ”€â”€ listings.py
â”‚   â”‚   â”œâ”€â”€ sales.py
â”‚   â”‚   â””â”€â”€ tasks.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ encryption.py          # ì•”í˜¸í™”
â”‚       â”œâ”€â”€ rate_limiter.py        # ì†ë„ ì œí•œ
â”‚       â””â”€â”€ logger.py              # ë¡œê¹…
â”‚
â”œâ”€â”€ crawlers/                      # í¬ë¡¤ëŸ¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_crawler.py            # ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ kyobo_crawler.py           # êµë³´ë¬¸ê³ 
â”‚   â”œâ”€â”€ yes24_crawler.py           # YES24 (í™•ì¥ìš©)
â”‚   â””â”€â”€ aladin_crawler.py          # ì•Œë¼ë”˜ (í™•ì¥ìš©)
â”‚
â”œâ”€â”€ uploaders/                     # ì—…ë¡œë” ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_uploader.py           # ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ csv_uploader.py            # CSV ìƒì„±
â”‚   â””â”€â”€ playwright_uploader.py     # ë¸Œë¼ìš°ì € ìë™í™”
â”‚
â”œâ”€â”€ analyzers/                     # ë¶„ì„ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ exposure_analyzer.py       # ë…¸ì¶œ ë¶„ì„
â”‚   â”œâ”€â”€ conversion_analyzer.py     # ì „í™˜ ë¶„ì„
â”‚   â””â”€â”€ recommendation_engine.py   # ì•¡ì…˜ ì¶”ì²œ
â”‚
â”œâ”€â”€ dashboard/                     # Streamlit ëŒ€ì‹œë³´ë“œ
â”‚   â”œâ”€â”€ Home.py                    # ë©”ì¸ í˜ì´ì§€
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ“Š_ì˜¤ëŠ˜_í• _ì¼.py
â”‚   â”‚   â”œâ”€â”€ 2_ğŸ“ˆ_íŒë§¤_ë¶„ì„.py
â”‚   â”‚   â”œâ”€â”€ 3_â¬†ï¸_ì—…ë¡œë“œ_ê´€ë¦¬.py
â”‚   â”‚   â””â”€â”€ 4_âš™ï¸_ì„¤ì •.py
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ charts.py
â”‚
â”œâ”€â”€ data/                          # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ raw/                       # í¬ë¡¤ë§ ì›ë³¸
â”‚   â”œâ”€â”€ processed/                 # ê°€ê³µëœ ë°ì´í„°
â”‚   â”œâ”€â”€ uploads/                   # ì—…ë¡œë“œìš© CSV
â”‚   â””â”€â”€ reports/                   # ë¶„ì„ ë¦¬í¬íŠ¸
â”‚
â”œâ”€â”€ sessions/                      # ê³„ì • ì„¸ì…˜ (Git ì œì™¸)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ logs/                          # ë¡œê·¸ íŒŒì¼
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ tests/                         # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_crawlers.py
â”‚   â”œâ”€â”€ test_uploaders.py
â”‚   â””â”€â”€ test_analyzers.py
â”‚
â””â”€â”€ scripts/                       # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ init_db.py                 # DB ì´ˆê¸°í™”
    â”œâ”€â”€ crawl_kyobo.py             # ìˆ˜ë™ í¬ë¡¤ë§
    â”œâ”€â”€ generate_csv.py            # CSV ìƒì„±
    â””â”€â”€ scheduler.py               # ìŠ¤ì¼€ì¤„ëŸ¬
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### ERD ê°œë…ë„
```
accounts (ê³„ì • ì •ë³´)
    â†“
listings (ê³„ì •ë³„ ìƒí’ˆ ë“±ë¡)
    â†“
products (ìƒí’ˆ ë§ˆìŠ¤í„°) â† kyobo_products (í¬ë¡¤ë§ ì›ë³¸)
    â†“
sales (íŒë§¤ ë°ì´í„°)
    â†“
analysis_results (ë¶„ì„ ê²°ê³¼)
```

### í…Œì´ë¸” ì •ì˜

#### 1. accounts (ê³„ì • ì •ë³´)
```sql
CREATE TABLE accounts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    account_name VARCHAR(50) NOT NULL UNIQUE,  -- 'account_1', 'account_2', ...
    email VARCHAR(100) NOT NULL,
    password_encrypted TEXT NOT NULL,          -- ì•”í˜¸í™”ëœ ë¹„ë°€ë²ˆí˜¸
    session_file VARCHAR(255),                 -- Playwright ì„¸ì…˜ íŒŒì¼ ê²½ë¡œ
    is_active BOOLEAN DEFAULT TRUE,
    last_login_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 2. kyobo_products (êµë³´ë¬¸ê³  í¬ë¡¤ë§ ì›ë³¸)
```sql
CREATE TABLE kyobo_products (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    isbn VARCHAR(13) UNIQUE NOT NULL,
    title VARCHAR(500) NOT NULL,
    author VARCHAR(200),
    publisher VARCHAR(100),
    publish_date DATE,
    original_price INTEGER NOT NULL,           -- ì •ê°€
    category VARCHAR(100),
    subcategory VARCHAR(100),
    image_url TEXT,
    description TEXT,
    kyobo_url TEXT,
    crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_processed BOOLEAN DEFAULT FALSE         -- products í…Œì´ë¸”ë¡œ ë³€í™˜ ì—¬ë¶€
);
```

#### 3. products (ìƒí’ˆ ë§ˆìŠ¤í„°)
```sql
CREATE TABLE products (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    isbn VARCHAR(13) UNIQUE NOT NULL,
    product_name VARCHAR(500) NOT NULL,        -- ìµœì í™”ëœ ìƒí’ˆëª…
    original_price INTEGER NOT NULL,           -- ì •ê°€
    sale_price INTEGER NOT NULL,               -- íŒë§¤ê°€ (ì •ê°€ Ã— 0.9)
    publisher VARCHAR(100),
    category VARCHAR(100),
    description TEXT,                          -- ìë™ ìƒì„±ëœ ìƒì„¸ ì„¤ëª…
    main_image_url TEXT,
    detail_images JSON,                        -- ["url1", "url2", ...]
    keywords JSON,                             -- ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...]
    status VARCHAR(20) DEFAULT 'ready',        -- ready, uploaded, selling, stopped
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (isbn) REFERENCES kyobo_products(isbn)
);
```

#### 4. listings (ê³„ì •ë³„ ìƒí’ˆ ë“±ë¡ í˜„í™©)
```sql
CREATE TABLE listings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    account_id INTEGER NOT NULL,
    product_id INTEGER NOT NULL,
    coupang_product_id VARCHAR(50),            -- ì¿ íŒ¡ ìƒí’ˆ ID
    seller_sku VARCHAR(100),                   -- íŒë§¤ì SKU
    listing_status VARCHAR(20) DEFAULT 'pending', -- pending, uploaded, active, stopped
    upload_method VARCHAR(20),                 -- csv, playwright
    uploaded_at TIMESTAMP,
    last_synced_at TIMESTAMP,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(account_id, product_id),
    FOREIGN KEY (account_id) REFERENCES accounts(id),
    FOREIGN KEY (product_id) REFERENCES products(id)
);
```

#### 5. sales (íŒë§¤ ë°ì´í„°)
```sql
CREATE TABLE sales (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    listing_id INTEGER NOT NULL,
    date DATE NOT NULL,
    views INTEGER DEFAULT 0,                   -- ì¡°íšŒìˆ˜
    clicks INTEGER DEFAULT 0,                  -- í´ë¦­ìˆ˜
    orders INTEGER DEFAULT 0,                  -- ì£¼ë¬¸ìˆ˜
    revenue INTEGER DEFAULT 0,                 -- ë§¤ì¶œ
    refunds INTEGER DEFAULT 0,                 -- í™˜ë¶ˆ
    stock INTEGER DEFAULT 0,                   -- ì¬ê³ 
    ranking INTEGER,                           -- ì¹´í…Œê³ ë¦¬ ìˆœìœ„
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(listing_id, date),
    FOREIGN KEY (listing_id) REFERENCES listings(id)
);
```

#### 6. analysis_results (ë¶„ì„ ê²°ê³¼)
```sql
CREATE TABLE analysis_results (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    listing_id INTEGER NOT NULL,
    analysis_date DATE NOT NULL,
    period_days INTEGER DEFAULT 7,             -- ë¶„ì„ ê¸°ê°„ (7ì¼/30ì¼)
    total_views INTEGER,
    total_orders INTEGER,
    conversion_rate REAL,                      -- ì „í™˜ìœ¨ (%)
    problem_type VARCHAR(50),                  -- exposure_low, conversion_low, normal
    priority_score REAL,                       -- ìš°ì„ ìˆœìœ„ ì ìˆ˜ (0-100)
    recommended_actions JSON,                  -- [{"action": "...", "reason": "..."}]
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (listing_id) REFERENCES listings(id)
);
```

#### 7. tasks (ì‘ì—… ë¡œê·¸)
```sql
CREATE TABLE tasks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    task_type VARCHAR(50) NOT NULL,            -- crawl, upload, analyze
    status VARCHAR(20) DEFAULT 'pending',      -- pending, running, success, failed
    params JSON,                               -- ì‘ì—… íŒŒë¼ë¯¸í„°
    result JSON,                               -- ì‘ì—… ê²°ê³¼
    error_message TEXT,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## ëª¨ë“ˆ ì„¤ê³„

### 1. Crawler Service

```python
# app/services/crawler_service.py

from typing import List, Dict
from crawlers.kyobo_crawler import KyoboCrawler
from app.models.kyobo_product import KyoboProduct

class CrawlerService:
    """í¬ë¡¤ë§ ì„œë¹„ìŠ¤"""

    async def crawl_new_books(
        self,
        category: str = "ì´ˆë“±êµì¬",
        limit: int = 50
    ) -> List[Dict]:
        """ì‹ ê°„ í¬ë¡¤ë§"""
        crawler = KyoboCrawler()
        raw_data = await crawler.crawl(category, limit)

        # DB ì €ì¥
        saved_products = []
        for item in raw_data:
            product = await self._save_kyobo_product(item)
            saved_products.append(product)

        return saved_products

    async def _save_kyobo_product(self, data: Dict) -> KyoboProduct:
        """í¬ë¡¤ë§ ë°ì´í„° DB ì €ì¥"""
        # ì¤‘ë³µ ì²´í¬ (ISBN)
        # ì €ì¥ ë¡œì§
        pass
```

### 2. Product Service

```python
# app/services/product_service.py

class ProductService:
    """ìƒí’ˆ ìƒì„±/ê´€ë¦¬ ì„œë¹„ìŠ¤"""

    async def create_product_from_kyobo(
        self,
        kyobo_product_id: int
    ) -> Product:
        """êµë³´ë¬¸ê³  ë°ì´í„° â†’ ì¿ íŒ¡ ìƒí’ˆ ìƒì„±"""
        kyobo = await self._get_kyobo_product(kyobo_product_id)

        product_data = {
            "isbn": kyobo.isbn,
            "product_name": self._optimize_title(kyobo.title),
            "original_price": kyobo.original_price,
            "sale_price": int(kyobo.original_price * 0.9),
            "publisher": kyobo.publisher,
            "category": kyobo.category,
            "description": self._generate_description(kyobo),
            "keywords": self._extract_keywords(kyobo),
            "main_image_url": kyobo.image_url
        }

        return await Product.create(**product_data)

    def _optimize_title(self, original_title: str) -> str:
        """ìƒí’ˆëª… ìµœì í™” (SEO í‚¤ì›Œë“œ ì¶”ê°€)"""
        # "ì´ˆë“± ìˆ˜í•™ ë¬¸ì œì§‘ 3í•™ë…„"
        # â†’ "ì´ˆë“± ìˆ˜í•™ ë¬¸ì œì§‘ 3í•™ë…„ [2025 ìµœì‹ íŒ] 10% í• ì¸"
        pass

    def _generate_description(self, kyobo) -> str:
        """ìƒì„¸ ì„¤ëª… ìë™ ìƒì„±"""
        template = f"""
        ğŸ“š {kyobo.title}

        âœ… ì¶œíŒì‚¬: {kyobo.publisher}
        âœ… ì •ê°€: {kyobo.original_price:,}ì›
        âœ… í• ì¸ê°€: {int(kyobo.original_price * 0.9):,}ì› (10% í• ì¸)

        {kyobo.description}
        """
        return template.strip()
```

### 3. Uploader Service

```python
# app/services/uploader_service.py

class UploaderService:
    """ì—…ë¡œë“œ ì„œë¹„ìŠ¤"""

    async def upload_to_accounts(
        self,
        product_id: int,
        account_ids: List[int],
        method: str = "csv"  # csv or playwright
    ):
        """ì—¬ëŸ¬ ê³„ì •ì— ìƒí’ˆ ì—…ë¡œë“œ"""
        product = await Product.get(product_id)

        for account_id in account_ids:
            if method == "csv":
                await self._upload_via_csv(product, account_id)
            else:
                await self._upload_via_playwright(product, account_id)

    async def _upload_via_csv(self, product, account_id):
        """CSV ëŒ€ëŸ‰ë“±ë¡"""
        csv_data = self._generate_csv_row(product)
        # CSV íŒŒì¼ì— ì¶”ê°€
        # listings í…Œì´ë¸” ì—…ë°ì´íŠ¸
        pass

    async def _upload_via_playwright(self, product, account_id):
        """ë¸Œë¼ìš°ì € ìë™í™” ì—…ë¡œë“œ"""
        from uploaders.playwright_uploader import PlaywrightUploader

        uploader = PlaywrightUploader(account_id)
        result = await uploader.upload(product)

        # listings í…Œì´ë¸” ì—…ë°ì´íŠ¸
        await Listing.create(
            account_id=account_id,
            product_id=product.id,
            listing_status='uploaded',
            upload_method='playwright',
            uploaded_at=datetime.now()
        )
```

### 4. Analyzer Service

```python
# app/services/analyzer_service.py

class AnalyzerService:
    """íŒë§¤ ë¶„ì„ ì„œë¹„ìŠ¤"""

    async def analyze_listing(
        self,
        listing_id: int,
        period_days: int = 7
    ) -> Dict:
        """ê°œë³„ ìƒí’ˆ ë¶„ì„"""
        sales_data = await self._get_sales_data(listing_id, period_days)

        total_views = sum(s.views for s in sales_data)
        total_orders = sum(s.orders for s in sales_data)

        # ë¶„ë¥˜
        if total_views < 10:
            problem_type = "exposure_low"
            actions = [
                {"action": "ìƒí’ˆëª… í‚¤ì›Œë“œ ìµœì í™”", "reason": "ê²€ìƒ‰ ë…¸ì¶œ ë¶€ì¡±"},
                {"action": "ì¹´í…Œê³ ë¦¬ ì¬ì„¤ì •", "reason": "ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ê°€ëŠ¥ì„±"},
                {"action": "ëŒ€í‘œ ì´ë¯¸ì§€ êµì²´", "reason": "í´ë¦­ ìœ ë„ ë¶€ì¡±"}
            ]
        elif total_views > 50 and total_orders == 0:
            problem_type = "conversion_low"
            actions = [
                {"action": "ê°€ê²© ê²€í† ", "reason": "ê²½ìŸì‚¬ ëŒ€ë¹„ ë†’ì„ ê°€ëŠ¥ì„±"},
                {"action": "ìƒì„¸ í˜ì´ì§€ ë³´ê°•", "reason": "êµ¬ë§¤ ì„¤ë“ë ¥ ë¶€ì¡±"},
                {"action": "ë¦¬ë·° í™•ë³´", "reason": "ì‹ ë¢°ë„ ë¶€ì¡±"}
            ]
        else:
            problem_type = "normal"
            actions = [{"action": "í˜„ì¬ ìœ ì§€", "reason": "ì •ìƒ íŒë§¤ ì¤‘"}]

        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
        priority_score = self._calculate_priority(
            total_views,
            total_orders,
            problem_type
        )

        # ì €ì¥
        result = await AnalysisResult.create(
            listing_id=listing_id,
            analysis_date=date.today(),
            period_days=period_days,
            total_views=total_views,
            total_orders=total_orders,
            conversion_rate=(total_orders / total_views * 100) if total_views > 0 else 0,
            problem_type=problem_type,
            priority_score=priority_score,
            recommended_actions=actions
        )

        return result

    def _calculate_priority(self, views, orders, problem_type) -> float:
        """ìš°ì„ ìˆœìœ„ ì ìˆ˜ (0-100)"""
        # ì¡°íšŒëŠ” ë§ì€ë° êµ¬ë§¤ ì—†ìœ¼ë©´ ë†’ì€ ì ìˆ˜ (ê°œì„  ê°€ëŠ¥ì„± ë†’ìŒ)
        if problem_type == "conversion_low":
            return min(100, views * 2)

        # ë…¸ì¶œ ë¶€ì¡±ì´ë©´ ì¤‘ê°„ ì ìˆ˜
        elif problem_type == "exposure_low":
            return 50

        # ì •ìƒì´ë©´ ë‚®ì€ ì ìˆ˜
        else:
            return 10
```

---

## ë°ì´í„° í”Œë¡œìš°

### ì „ì²´ íë¦„ë„

```
[1. í¬ë¡¤ë§ ë‹¨ê³„]
êµë³´ë¬¸ê³  â†’ KyoboCrawler â†’ kyobo_products í…Œì´ë¸”
         (ë§¤ì¼ ìë™)

[2. ìƒí’ˆ ìƒì„± ë‹¨ê³„]
kyobo_products â†’ ProductService â†’ products í…Œì´ë¸”
              (ìˆ˜ë™ ìŠ¹ì¸ or ìë™)

[3. ì—…ë¡œë“œ ë‹¨ê³„]
products â†’ UploaderService â†’ CSV ìƒì„± or Playwright
        â†’ listings í…Œì´ë¸” (ê³„ì •ë³„ 5ê°œ ë ˆì½”ë“œ)

[4. íŒë§¤ ë°ì´í„° ìˆ˜ì§‘]
ì¿ íŒ¡ íŒë§¤ìì„¼í„° ë¦¬í¬íŠ¸ â†’ íŒŒì¼ ì—…ë¡œë“œ â†’ sales í…Œì´ë¸”

[5. ë¶„ì„ ë‹¨ê³„]
sales â†’ AnalyzerService â†’ analysis_results í…Œì´ë¸”

[6. ì•¡ì…˜ ì¶”ì²œ]
analysis_results â†’ ëŒ€ì‹œë³´ë“œ â†’ ì—„ë§ˆê°€ ìŠ¹ì¸ â†’ ìë™ ì‹¤í–‰
```

### ìƒì„¸ ì‹œí€€ìŠ¤ (í•˜ë£¨ ì¼ê³¼)

```
08:00 - [Celery Scheduler] í¬ë¡¤ë§ ì‘ì—… ì‹œì‘
  â”œâ”€ KyoboCrawler.crawl("ì´ˆë“±êµì¬", limit=50)
  â”œâ”€ ì‹ ê°„ 30ê¶Œ ë°œê²¬
  â””â”€ kyobo_products í…Œì´ë¸” ì €ì¥

09:00 - [Celery] ìƒí’ˆ ìƒì„± ì‘ì—…
  â”œâ”€ ë¯¸ì²˜ë¦¬ kyobo_products ì¡°íšŒ
  â”œâ”€ ProductService.create_product_from_kyobo()
  â”‚   â”œâ”€ ìƒí’ˆëª… ìµœì í™”
  â”‚   â”œâ”€ ê°€ê²© ê³„ì‚° (ì •ê°€ Ã— 0.9)
  â”‚   â””â”€ í‚¤ì›Œë“œ ì¶”ì¶œ
  â””â”€ products í…Œì´ë¸” ì €ì¥ (30ê°œ)

10:00 - [ì•Œë¦¼] ì—„ë§ˆì—ê²Œ ì¹´í†¡/ì´ë©”ì¼
  "ì‹ ê·œ ìƒí’ˆ 30ê°œ ì¤€ë¹„ë¨. ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤."

11:00 - [ì—„ë§ˆ ì‘ì—…] ëŒ€ì‹œë³´ë“œ ì ‘ì†
  â”œâ”€ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ í™•ì¸
  â”œâ”€ [ì¼ê´„ ìŠ¹ì¸] ë²„íŠ¼ í´ë¦­
  â””â”€ upload_task íì— ì¶”ê°€

11:05 - [Celery] ì—…ë¡œë“œ ì‘ì—… ì‹œì‘
  â”œâ”€ ê³„ì • 1: 30ê°œ ìƒí’ˆ ì—…ë¡œë“œ (CSV ìƒì„±)
  â”œâ”€ 30ë¶„ ëŒ€ê¸°
  â”œâ”€ ê³„ì • 2: 30ê°œ ìƒí’ˆ ì—…ë¡œë“œ
  â”œâ”€ ...
  â””â”€ ê³„ì • 5 ì™„ë£Œ (ì´ 2.5ì‹œê°„)

14:00 - [ì™„ë£Œ ì•Œë¦¼]
  "150ê°œ ìƒí’ˆ ì—…ë¡œë“œ ì™„ë£Œ (30ê°œ Ã— 5ê³„ì •)"

18:00 - [Celery] íŒë§¤ ë°ì´í„° ìˆ˜ì§‘
  â”œâ”€ íŒë§¤ìì„¼í„° ë¡œê·¸ì¸ (5ê°œ ê³„ì •)
  â”œâ”€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ
  â””â”€ sales í…Œì´ë¸” ì—…ë°ì´íŠ¸

19:00 - [Celery] íŒë§¤ ë¶„ì„
  â”œâ”€ 7ì¼ê°„ íŒë§¤ 0ê±´ ìƒí’ˆ ì¶”ì¶œ (50ê°œ)
  â”œâ”€ AnalyzerService.analyze_listing()
  â””â”€ ìš°ì„ ìˆœìœ„ TOP 10 ì„ ì •

20:00 - [ì•Œë¦¼] ì£¼ê°„ ë¦¬í¬íŠ¸
  "ì´ë²ˆ ì£¼ ê°œì„  í•„ìš” ìƒí’ˆ 10ê°œ"
  + ëŒ€ì‹œë³´ë“œ ë§í¬
```

---

## API ì„¤ê³„

### REST API ì—”ë“œí¬ì¸íŠ¸

```python
# app/api/products.py

from fastapi import APIRouter, Depends
from typing import List
from app.schemas.product import ProductResponse, ProductCreate

router = APIRouter(prefix="/api/products", tags=["products"])

@router.get("/", response_model=List[ProductResponse])
async def get_products(
    skip: int = 0,
    limit: int = 100,
    status: str = None
):
    """ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
    pass

@router.post("/", response_model=ProductResponse)
async def create_product(product: ProductCreate):
    """ìƒí’ˆ ìƒì„±"""
    pass

@router.get("/{product_id}", response_model=ProductResponse)
async def get_product(product_id: int):
    """ìƒí’ˆ ìƒì„¸ ì¡°íšŒ"""
    pass

@router.post("/{product_id}/upload")
async def upload_product(
    product_id: int,
    account_ids: List[int],
    method: str = "csv"
):
    """ìƒí’ˆ ì—…ë¡œë“œ"""
    # Celery ì‘ì—… íì— ì¶”ê°€
    from app.tasks.upload_tasks import upload_to_accounts
    task = upload_to_accounts.delay(product_id, account_ids, method)
    return {"task_id": task.id}
```

```python
# app/api/sales.py

router = APIRouter(prefix="/api/sales", tags=["sales"])

@router.get("/listings/{listing_id}")
async def get_listing_sales(
    listing_id: int,
    days: int = 7
):
    """íŠ¹ì • ìƒí’ˆì˜ íŒë§¤ ë°ì´í„°"""
    pass

@router.get("/analysis/{listing_id}")
async def get_listing_analysis(listing_id: int):
    """íŠ¹ì • ìƒí’ˆì˜ ë¶„ì„ ê²°ê³¼"""
    pass

@router.get("/recommendations")
async def get_recommendations(limit: int = 10):
    """ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ì¶”ì²œ TOP N"""
    pass
```

```python
# app/api/tasks.py

router = APIRouter(prefix="/api/tasks", tags=["tasks"])

@router.post("/crawl")
async def start_crawl_task(
    category: str = "ì´ˆë“±êµì¬",
    limit: int = 50
):
    """í¬ë¡¤ë§ ì‘ì—… ì‹œì‘"""
    from app.tasks.crawl_tasks import crawl_kyobo
    task = crawl_kyobo.delay(category, limit)
    return {"task_id": task.id}

@router.get("/status/{task_id}")
async def get_task_status(task_id: str):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    from celery.result import AsyncResult
    result = AsyncResult(task_id)
    return {
        "status": result.status,
        "result": result.result if result.ready() else None
    }
```

---

## ë°°í¬ ì „ëµ

### Docker Compose êµ¬ì„±

```yaml
# docker-compose.yml

version: '3.8'

services:
  # FastAPI ë°±ì—”ë“œ
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/coupang_auto
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./app:/app
      - ./data:/data
      - ./sessions:/sessions
    depends_on:
      - db
      - redis
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Celery Worker
  celery_worker:
    build: .
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/coupang_auto
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./app:/app
      - ./data:/data
      - ./sessions:/sessions
    depends_on:
      - db
      - redis
    command: celery -A app.tasks worker --loglevel=info

  # Celery Beat (ìŠ¤ì¼€ì¤„ëŸ¬)
  celery_beat:
    build: .
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/coupang_auto
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    command: celery -A app.tasks beat --loglevel=info

  # Streamlit ëŒ€ì‹œë³´ë“œ
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.dashboard
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
    volumes:
      - ./dashboard:/dashboard
    command: streamlit run dashboard/Home.py

  # PostgreSQL
  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=coupang_auto
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  # Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

### í™˜ê²½ë³€ìˆ˜ (.env)

```env
# .env.example

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/coupang_auto

# Redis
REDIS_URL=redis://localhost:6379/0

# Encryption
ENCRYPTION_KEY=your-32-byte-key-here

# Coupang Accounts (ì•”í˜¸í™”ëœ ê°’)
ACCOUNT_1_EMAIL=encrypted_email_1
ACCOUNT_1_PASSWORD=encrypted_password_1
# ... 5ê°œ ê³„ì •

# Crawler Settings
CRAWL_DELAY_MIN=1
CRAWL_DELAY_MAX=3
CRAWL_MAX_ITEMS=100

# Upload Settings
UPLOAD_DELAY_MIN=5
UPLOAD_DELAY_MAX=10
UPLOAD_MAX_DAILY=20

# Notification
KAKAO_API_KEY=your_kakao_key
EMAIL_SMTP_SERVER=smtp.gmail.com
EMAIL_SMTP_PORT=587
EMAIL_FROM=your@email.com
EMAIL_TO=mom@email.com
```

### ì‹¤í–‰ ë°©ë²•

```bash
# 1. í™˜ê²½ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ ìˆ˜ì •

# 2. Docker ì»¨í…Œì´ë„ˆ ì‹œì‘
docker-compose up -d

# 3. DB ì´ˆê¸°í™”
docker-compose exec api python scripts/init_db.py

# 4. ê³„ì • ì •ë³´ ë“±ë¡ (ì•”í˜¸í™”)
docker-compose exec api python scripts/register_accounts.py

# 5. ëŒ€ì‹œë³´ë“œ ì ‘ì†
# http://localhost:8501

# 6. API ë¬¸ì„œ
# http://localhost:8000/docs
```

---

## ë³´ì•ˆ ì„¤ê³„

### ê³„ì • ì •ë³´ ì•”í˜¸í™”

```python
# app/utils/encryption.py

from cryptography.fernet import Fernet
import os

class EncryptionManager:
    def __init__(self):
        key = os.getenv("ENCRYPTION_KEY").encode()
        self.cipher = Fernet(key)

    def encrypt(self, plaintext: str) -> str:
        """ì•”í˜¸í™”"""
        return self.cipher.encrypt(plaintext.encode()).decode()

    def decrypt(self, ciphertext: str) -> str:
        """ë³µí˜¸í™”"""
        return self.cipher.decrypt(ciphertext.encode()).decode()

# ì‚¬ìš© ì˜ˆì‹œ
encryptor = EncryptionManager()

# ê³„ì • ì •ë³´ ì €ì¥ ì‹œ
email_encrypted = encryptor.encrypt("seller1@example.com")
password_encrypted = encryptor.encrypt("password123")

# ì‚¬ìš© ì‹œ
email = encryptor.decrypt(email_encrypted)
password = encryptor.decrypt(password_encrypted)
```

### Rate Limiting

```python
# app/utils/rate_limiter.py

import time
import random
from functools import wraps

class RateLimiter:
    """ì†ë„ ì œí•œ"""

    def __init__(self, min_delay: float = 1.0, max_delay: float = 3.0):
        self.min_delay = min_delay
        self.max_delay = max_delay
        self.last_request_time = {}

    def wait(self, key: str = "default"):
        """ìš”ì²­ ì „ ëŒ€ê¸°"""
        now = time.time()

        if key in self.last_request_time:
            elapsed = now - self.last_request_time[key]
            required_delay = random.uniform(self.min_delay, self.max_delay)

            if elapsed < required_delay:
                sleep_time = required_delay - elapsed
                time.sleep(sleep_time)

        self.last_request_time[key] = time.time()

# ì‚¬ìš© ì˜ˆì‹œ
limiter = RateLimiter(min_delay=1.0, max_delay=3.0)

for product in products:
    limiter.wait("kyobo_crawler")
    crawl(product)
```

---

## ëª¨ë‹ˆí„°ë§/ë¡œê¹…

```python
# app/utils/logger.py

import logging
from logging.handlers import RotatingFileHandler
import os

def setup_logger(name: str, log_file: str = None):
    """ë¡œê±° ì„¤ì •"""
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)

    # í¬ë§·
    formatter = logging.Formatter(
        '[%(asctime)s] %(levelname)s [%(name)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # íŒŒì¼ í•¸ë“¤ëŸ¬
    if log_file:
        os.makedirs("logs", exist_ok=True)
        file_handler = RotatingFileHandler(
            f"logs/{log_file}",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger

# ì‚¬ìš© ì˜ˆì‹œ
logger = setup_logger("crawler", "crawler.log")
logger.info("í¬ë¡¤ë§ ì‹œì‘")
logger.error("í¬ë¡¤ë§ ì‹¤íŒ¨", exc_info=True)
```

---

## í™•ì¥ ê°€ëŠ¥ì„±

### Phase 1 (MVP - 1~2ì£¼)
- êµë³´ë¬¸ê³  í¬ë¡¤ë§
- CSV ëŒ€ëŸ‰ë“±ë¡
- ê°„ë‹¨í•œ íŒë§¤ ë¶„ì„
- Streamlit ëŒ€ì‹œë³´ë“œ

### Phase 2 (V1 - 3~4ì£¼)
- Playwright ìë™ ì—…ë¡œë“œ
- 5ê°œ ê³„ì • ë™ì‹œ ìš´ì˜
- ë…¸ì¶œ/ì „í™˜ ë¶„ì„
- ìš°ì„ ìˆœìœ„ ì¶”ì²œ

### Phase 3 (V2 - ì´í›„)
- YES24, ì•Œë¼ë”˜ í¬ë¡¤ë§ ì¶”ê°€
- ê°€ê²© ëª¨ë‹ˆí„°ë§ (ê²½ìŸì‚¬)
- A/B í…ŒìŠ¤íŠ¸ (ê³„ì •ë³„ ì „ëµ ë¹„êµ)
- LLM ê¸°ë°˜ ìƒí’ˆëª…/ì„¤ëª… ìë™ ìƒì„±
- ìë™ ë¦¬ë·° ì‘ë‹µ

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ì§€ê¸ˆ ë°”ë¡œ**: í´ë” êµ¬ì¡° ìƒì„± + requirements.txt ì‘ì„±
2. **ë‚´ì¼**: DB ìŠ¤í‚¤ë§ˆ êµ¬í˜„ + ì²« í¬ë¡¤ëŸ¬ ì‘ì„±
3. **ëª¨ë ˆ**: CSV ìƒì„± ë¡œì§ + ëŒ€ì‹œë³´ë“œ í”„ë¡œí† íƒ€ì…

ì–´ë–¤ ë¶€ë¶„ë¶€í„° ì‹œì‘í• ê¹Œìš”?
