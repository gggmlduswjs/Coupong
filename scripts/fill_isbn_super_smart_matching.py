"""
ì´ˆê°•ë ¥ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ìœ¼ë¡œ ISBN ì±„ìš°ê¸°

Books í…Œì´ë¸” í™œìš©ì„ ê·¹ëŒ€í™”:
- ë‹¤ì–‘í•œ í‚¤ì›Œë“œ ì¡°í•© ì‹œë„
- ìˆ«ì ê³µë°± ì²˜ë¦¬ (ì§€êµ¬ê³¼í•™1 â†’ ì§€êµ¬ê³¼í•™ 1)
- EBS/ìˆ˜ëŠ¥íŠ¹ê°• íŒ¨í„´ íŠ¹í™”
- ì¶œíŒì‚¬ëª… í™œìš©
"""
import sys
import io
import re
import sqlite3
from datetime import datetime
from typing import Optional, List, Tuple

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def extract_search_patterns(product_name: str) -> List[str]:
    """
    ìƒí’ˆëª…ì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ íŒ¨í„´ ìƒì„±
    """
    patterns = []

    # 1. ìˆ˜ëŠ¥íŠ¹ê°• íŒ¨í„´
    if 'ìˆ˜ëŠ¥íŠ¹ê°•' in product_name:
        # "2027í•™ë…„ë„ ìˆ˜ëŠ¥íŠ¹ê°• ì§€êµ¬ê³¼í•™1" â†’ "EBS ìˆ˜ëŠ¥íŠ¹ê°• ì§€êµ¬ê³¼í•™ 1"
        # "ìˆ˜ëŠ¥íŠ¹ê°• í™”í•™1" â†’ "ìˆ˜ëŠ¥íŠ¹ê°• í™”í•™ 1"

        # ê³¼ëª© ì¶”ì¶œ
        subjects = ['ë¬¼ë¦¬', 'í™”í•™', 'ìƒëª…ê³¼í•™', 'ì§€êµ¬ê³¼í•™', 'í•œêµ­ì‚¬', 'ì‚¬íšŒë¬¸í™”', 'ìƒí™œê³¼ìœ¤ë¦¬',
                   'ìœ¤ë¦¬ì™€ì‚¬ìƒ', 'ì„¸ê³„ì§€ë¦¬', 'ë™ì•„ì‹œì•„ì‚¬', 'ì„¸ê³„ì‚¬', 'ê²½ì œ', 'ì •ì¹˜ì™€ë²•', 'ì‚¬íšŒ',
                   'êµ­ì–´', 'ì˜ì–´', 'ìˆ˜í•™', 'ë…ì„œ', 'ë¬¸í•™', 'ì–¸ì–´ì™€ë§¤ì²´', 'í™”ë²•ê³¼ì‘ë¬¸']

        for subject in subjects:
            if subject in product_name:
                # ìˆ«ì ì²˜ë¦¬ (ë¬¼ë¦¬1 â†’ ë¬¼ë¦¬ 1)
                subject_with_space = re.sub(r'(\D)(\d)', r'\1 \2', subject)

                patterns.append(f"ìˆ˜ëŠ¥íŠ¹ê°•%{subject}%")
                patterns.append(f"EBS ìˆ˜ëŠ¥íŠ¹ê°•%{subject}%")
                patterns.append(f"ìˆ˜ëŠ¥íŠ¹ê°•%{subject_with_space}%")
                break

    # 2. ê°œë…+ìœ í˜• / ê°œë…ì›ë¦¬ íŒ¨í„´
    if 'ê°œë…' in product_name and 'ìœ í˜•' in product_name:
        # "ê°œë…+ìœ í˜• ë¼ì´íŠ¸ ì¤‘í•™ ìˆ˜í•™ 1-1" â†’ "ê°œë… + ìœ í˜• ë¼ì´íŠ¸ ì¤‘í•™ ìˆ˜í•™ 1-1"
        grade_pattern = re.search(r'(ì´ˆë“±|ì¤‘ë“±|ì¤‘í•™|ê³ ë“±)\s*(\d)?', product_name)
        subject = None

        subjects = ['ìˆ˜í•™', 'ì˜ì–´', 'êµ­ì–´', 'ê³¼í•™', 'ì‚¬íšŒ']
        for s in subjects:
            if s in product_name:
                subject = s
                break

        if subject:
            if grade_pattern:
                level = grade_pattern.group(1)
                grade = grade_pattern.group(2) if grade_pattern.group(2) else ''
                patterns.append(f"ê°œë…%ìœ í˜•%{level}%{subject}%")
                if grade:
                    patterns.append(f"ê°œë…%ìœ í˜•%{level}%{grade}%{subject}%")
            else:
                patterns.append(f"ê°œë…%ìœ í˜•%{subject}%")

    # 3. 100ë°œ 100ì¤‘ íŒ¨í„´
    if '100ë°œ' in product_name or '100ì¤‘' in product_name:
        # "100ë°œ 100ì¤‘ ì¤‘í•™ ì˜ì–´ 3-1(ë™ì•„ ìœ¤ì •ë¯¸)" â†’ "100ë°œ 100ì¤‘%ì¤‘í•™ ì˜ì–´%"
        grade_pattern = re.search(r'(ì´ˆë“±|ì¤‘ë“±|ì¤‘í•™|ê³ ë“±)\s*(\d)?', product_name)
        subject = None

        subjects = ['ìˆ˜í•™', 'ì˜ì–´', 'êµ­ì–´', 'ê³¼í•™', 'ì‚¬íšŒ']
        for s in subjects:
            if s in product_name:
                subject = s
                break

        if subject and grade_pattern:
            level = grade_pattern.group(1)
            patterns.append(f"100ë°œ 100ì¤‘%{level}%{subject}%")

    # 4. ì‹œë¦¬ì¦ˆëª… íŒ¨í„´
    series = ['ì˜¤íˆ¬', 'ìˆ', 'ìì´ìŠ¤í† ë¦¬', 'ë§ˆë”í……', 'ì™„ì', 'í•œë', 'í’ì‚°ì', 'ì¼í’ˆ']
    for s in series:
        if s in product_name:
            # "ì˜¤íˆ¬ ì¤‘ë“± ê³¼í•™ 2-1" â†’ "ì˜¤íˆ¬%ì¤‘ë“±%ê³¼í•™%"
            grade_pattern = re.search(r'(ì´ˆë“±|ì¤‘ë“±|ì¤‘í•™|ê³ ë“±)\s*(\d)?', product_name)
            subject = None

            subjects_list = ['ìˆ˜í•™', 'ì˜ì–´', 'êµ­ì–´', 'ê³¼í•™', 'ì‚¬íšŒ', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒëª…ê³¼í•™', 'ì§€êµ¬ê³¼í•™']
            for subj in subjects_list:
                if subj in product_name:
                    subject = subj
                    break

            if subject:
                if grade_pattern:
                    level = grade_pattern.group(1)
                    patterns.append(f"{s}%{level}%{subject}%")
                else:
                    patterns.append(f"{s}%{subject}%")

    # 5. ì¼ë°˜ íŒ¨í„´ (ì• 3ë‹¨ì–´)
    clean = re.sub(r'\([^)]*\)', '', product_name)
    clean = re.sub(r'\+ì‚¬ì€í’ˆ|\+ì„ ë¬¼|ì‚¬ì€í’ˆ|ì„ ë¬¼', '', clean)
    clean = re.sub(r'\s+', ' ', clean).strip()

    words = clean.split()[:3]
    if len(words) >= 2:
        patterns.append('%'.join(words) + '%')

    return patterns


def find_isbn_super_smart(product_name: str, conn) -> Optional[Tuple[str, str, float]]:
    """
    ì´ˆê°•ë ¥ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ìœ¼ë¡œ ISBN ì°¾ê¸°

    Returns:
        (isbn, matched_title, confidence) ë˜ëŠ” None
    """
    patterns = extract_search_patterns(product_name)

    if not patterns:
        return None

    cursor = conn.cursor()

    for idx, pattern in enumerate(patterns):
        try:
            cursor.execute("""
                SELECT isbn, title
                FROM books
                WHERE title LIKE ?
                LIMIT 1
            """, (pattern,))

            result = cursor.fetchone()
            if result:
                # ì‹ ë¢°ë„: ì²« ë²ˆì§¸ íŒ¨í„´ì¼ìˆ˜ë¡ ë†’ìŒ
                confidence = 1.0 - (idx * 0.1)
                return (result[0], result[1], confidence)
        except Exception as e:
            continue

    return None


def fill_isbn_super_smart_matching(
    dry_run: bool = False,
    limit: int = None,
    db_path: str = 'coupang_auto_backup.db',
    account_id: int = None
):
    """
    ì´ˆê°•ë ¥ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ìœ¼ë¡œ ISBN ì±„ìš°ê¸°
    """
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    print("=" * 80)
    print("ì´ˆê°•ë ¥ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ìœ¼ë¡œ ISBN ì±„ìš°ê¸°")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN' if dry_run else 'LIVE'}")
    if limit:
        print(f"ì œí•œ: {limit}ê°œ")
    if account_id:
        print(f"ê³„ì •: ID {account_id}")
    print()

    # ISBN ì—†ëŠ” ìƒí’ˆ ì¡°íšŒ
    query = """
        SELECT id, account_id, product_name
        FROM listings
        WHERE (isbn IS NULL OR isbn = '')
        AND product_name IS NOT NULL
        AND product_name != ''
    """

    params = []
    if account_id:
        query += " AND account_id = ?"
        params.append(account_id)

    query += " ORDER BY id"

    if limit:
        query += f" LIMIT {limit}"

    cursor = conn.cursor()
    cursor.execute(query, params)
    candidates = cursor.fetchall()

    print(f"ğŸ” ëŒ€ìƒ: {len(candidates):,}ê°œ")
    print()

    stats = {
        'total': len(candidates),
        'success': 0,
        'failed': 0,
        'duplicate': 0,
        'by_confidence': {
            '90-100%': 0,
            '80-90%': 0,
            '70-80%': 0,
        }
    }

    updated_listings = []

    for idx, row in enumerate(candidates, 1):
        listing_id = row[0]
        acc_id = row[1]
        product_name = row[2]

        result = find_isbn_super_smart(product_name, conn)

        if result:
            isbn, matched_title, confidence = result
            stats['success'] += 1

            # ì‹ ë¢°ë„ ë¶„ë¥˜
            if confidence >= 0.9:
                stats['by_confidence']['90-100%'] += 1
            elif confidence >= 0.8:
                stats['by_confidence']['80-90%'] += 1
            else:
                stats['by_confidence']['70-80%'] += 1

            updated_listings.append((listing_id, isbn, product_name, matched_title, confidence))

            if stats['success'] <= 20:
                print(f"âœ“ [{stats['success']}] {product_name[:60]}")
                print(f"   â†’ ISBN: {isbn} | ì‹ ë¢°ë„: {confidence*100:.0f}%")
                print(f"   â† {matched_title[:60]}")
        else:
            stats['failed'] += 1

        if idx % 100 == 0:
            print(f"ì§„í–‰: {idx:,}/{len(candidates):,} ({idx/len(candidates)*100:.1f}%) - ì„±ê³µ: {stats['success']:,}")

    print()
    print("=" * 80)
    print("ì²˜ë¦¬ ê²°ê³¼")
    print("=" * 80)
    print(f"ì´ ì²˜ë¦¬: {stats['total']:,}ê°œ")
    print(f"âœ… ì„±ê³µ: {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed']:,}ê°œ")
    print()

    if stats['success'] > 0:
        print("ğŸ“Š ì‹ ë¢°ë„ ë¶„í¬:")
        for range_name, count in sorted(stats['by_confidence'].items(), reverse=True):
            if count > 0:
                print(f"   {range_name}: {count:4d}ê°œ ({count/stats['success']*100:.1f}%)")
        print()

    if not dry_run and updated_listings:
        print("ğŸ’¾ ì—…ë°ì´íŠ¸ ì¤‘...")

        update_count = 0
        duplicate_count = 0

        for listing_id, isbn, product_name, matched_title, confidence in updated_listings:
            try:
                cursor = conn.cursor()

                cursor.execute("SELECT account_id FROM listings WHERE id = ?", (listing_id,))
                row = cursor.fetchone()
                if not row:
                    continue

                acc_id = row[0]

                # ì¤‘ë³µ ì²´í¬
                cursor.execute("""
                    SELECT COUNT(*) FROM listings
                    WHERE account_id = ? AND isbn = ? AND id != ?
                """, (acc_id, isbn, listing_id))

                if cursor.fetchone()[0] > 0:
                    duplicate_count += 1
                    continue

                cursor.execute("UPDATE listings SET isbn = ? WHERE id = ?", (isbn, listing_id))
                update_count += 1

                if update_count % 100 == 0:
                    conn.commit()
                    print(f"   ì²´í¬í¬ì¸íŠ¸: {update_count:,}ê°œ")

            except Exception as e:
                continue

        conn.commit()
        print(f"âœ… ì™„ë£Œ: {update_count:,}ê°œ")
        if duplicate_count > 0:
            print(f"âš ï¸  ì¤‘ë³µ: {duplicate_count:,}ê°œ")
    else:
        print("âš ï¸  DRY RUN")

    conn.close()

    print()
    print(f"ì¢…ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ì´ˆê°•ë ¥ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­')
    parser.add_argument('--dry-run', action='store_true')
    parser.add_argument('--limit', type=int)
    parser.add_argument('--db', type=str, default='coupang_auto_backup.db')
    parser.add_argument('--account', type=int)

    args = parser.parse_args()

    try:
        stats = fill_isbn_super_smart_matching(
            dry_run=args.dry_run,
            limit=args.limit,
            db_path=args.db,
            account_id=args.account
        )

        print()
        print(f"ğŸ“Š ì„±ê³µë¥ : {stats['success']/stats['total']*100:.1f}%")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
