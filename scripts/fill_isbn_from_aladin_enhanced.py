"""
Phase 3: ì•Œë¼ë”˜ API ê²€ìƒ‰ ê°•í™” ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ fill_isbn_from_aladin.pyì˜ ê°œì„  ë²„ì „:
- ì—°ë„ ë³´ì¡´ (ì œê±°í•˜ì§€ ì•Šê³  ê²€ìƒ‰ì— í™œìš©)
- í¼ë¸”ë¦¬ì…” í™œìš© (ê²°ê³¼ í•„í„°ë§)
- í‚¤ì›Œë“œ í™•ì¥ (5ë‹¨ì–´ â†’ 10ë‹¨ì–´)
- ì •ë ¬ ê°œì„  (ì—°ë„ ìˆìœ¼ë©´ PublishTime, ì—†ìœ¼ë©´ Accuracy)

ì˜ˆìƒ ì„±ê³¼: +1,000~1,500 ISBN (30-40ë¶„, ë³‘ë ¬ ì²˜ë¦¬ ì‹œ)
"""
import re
import sys
import io
import os
import time
from pathlib import Path
from datetime import datetime
from typing import Tuple, List, Optional, Dict

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

import sqlite3
from crawlers.aladin_api_crawler import AladinAPICrawler


def extract_year(product_name: str) -> Optional[int]:
    """
    ìƒí’ˆëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ

    íŒ¨í„´:
    - 2024, 2025, 2026, 2027 (20XX)
    - 2024ë…„, 2025ë…„

    Returns:
        ì—°ë„ (int) ë˜ëŠ” None
    """
    if not product_name:
        return None

    # "YYYYë…„" íŒ¨í„´
    match = re.search(r'(20\d{2})ë…„', product_name)
    if match:
        year = int(match.group(1))
        if 2020 <= year <= 2030:
            return year

    # "YYYY" íŒ¨í„´ (20XX)
    match = re.search(r'\b(20\d{2})\b', product_name)
    if match:
        year = int(match.group(1))
        if 2020 <= year <= 2030:
            return year

    return None


def extract_publisher(product_name: str) -> Optional[str]:
    """
    ìƒí’ˆëª…ì—ì„œ í¼ë¸”ë¦¬ì…” ì¶”ì¶œ

    íŒ¨í„´:
    - [í¼ë¸”ë¦¬ì…”ëª…]
    - (í¼ë¸”ë¦¬ì…”ëª…)

    Returns:
        í¼ë¸”ë¦¬ì…”ëª… ë˜ëŠ” None
    """
    if not product_name:
        return None

    # [ëŒ€ê´„í˜¸] íŒ¨í„´ ìš°ì„ 
    match = re.search(r'\[([^\]]+)\]', product_name)
    if match:
        publisher = match.group(1).strip()
        # ë„ˆë¬´ ê¸¸ì§€ ì•Šê³  ì˜ë¯¸ ìˆëŠ” ê²½ìš°ë§Œ
        if 2 <= len(publisher) <= 20:
            return publisher

    # (ì†Œê´„í˜¸) íŒ¨í„´
    match = re.search(r'\(([^)]+)\)', product_name)
    if match:
        publisher = match.group(1).strip()
        # ì—°ë„, ê¶Œìˆ˜, íŒ ì •ë³´ ì œì™¸
        if not re.search(r'^\d|ê¶Œ|íŒ|ì„¸íŠ¸', publisher):
            if 2 <= len(publisher) <= 20:
                return publisher

    return None


def clean_title_for_search_enhanced(product_name: str, preserve_year: bool = True) -> str:
    """
    ìƒí’ˆëª…ì„ ì•Œë¼ë”˜ ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¡œ ì •ë¦¬ (ê°•í™” ë²„ì „)

    ê°œì„ ì‚¬í•­:
    - ì—°ë„ ë³´ì¡´ ì˜µì…˜ (ê¸°ë³¸ê°’: True)
    - í¼ë¸”ë¦¬ì…” ì •ë³´ëŠ” ì œê±°í•˜ë˜ ë³„ë„ë¡œ ì¶”ì¶œ ê°€ëŠ¥
    - + & ê¸°í˜¸ëŠ” ì œê±° (ë¬¶ìŒ êµ¬ë¶„ì)

    Args:
        product_name: ì›ë³¸ ìƒí’ˆëª…
        preserve_year: Trueì´ë©´ ì—°ë„ ìœ ì§€, Falseì´ë©´ ì œê±°

    Returns:
        ì •ë¦¬ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ
    """
    if not product_name:
        return ""

    title = product_name

    # ê´„í˜¸ ì œê±° (í¼ë¸”ë¦¬ì…” ì •ë³´)
    title = re.sub(r'\[[^\]]*\]', '', title)
    title = re.sub(r'\([^)]*\)', '', title)

    # ì—°ë„ ì²˜ë¦¬
    if not preserve_year:
        title = re.sub(r'\d{4}ë…„?', '', title)
        title = re.sub(r'20\d{2}', '', title)

    # ì„¸íŠ¸, ê¶Œìˆ˜ ì œê±°
    title = re.sub(r'ì„¸íŠ¸\d*', '', title)
    title = re.sub(r'ì „\s*\d+ê¶Œ', '', title)
    title = re.sub(r'\d+ê¶Œ', '', title)

    # +, & ê¸°í˜¸ ì œê±° (ë¬¶ìŒ êµ¬ë¶„ì)
    title = re.sub(r'\s*[+&]\s*', ' ', title)

    # ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
    remove_words = ['ì„ ë¬¼', 'ì‚¬ì€í’ˆ', 'ì¦ì •', 'í¬í•¨', 'ë¬´ë£Œë°°ì†¡', 'ì˜ë ', 'ì„ íƒ']
    for word in remove_words:
        title = title.replace(word, '')

    # ê³µë°± ì •ë¦¬
    title = ' '.join(title.split())

    return title.strip()


def build_smart_aladin_query(product_name: str) -> Dict[str, any]:
    """
    ìŠ¤ë§ˆíŠ¸ ì•Œë¼ë”˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±

    ì „ëµ:
    1. ì—°ë„ê°€ ìˆìœ¼ë©´ ë³´ì¡´í•˜ê³  PublishTime ì •ë ¬
    2. ì—°ë„ê°€ ì—†ìœ¼ë©´ Accuracy ì •ë ¬
    3. í¼ë¸”ë¦¬ì…” ì¶”ì¶œí•˜ì—¬ ê²°ê³¼ í•„í„°ë§ìš©ìœ¼ë¡œ í™œìš©
    4. í‚¤ì›Œë“œëŠ” 10ë‹¨ì–´ê¹Œì§€ í™•ì¥

    Returns:
        {
            'keyword': ê²€ìƒ‰ í‚¤ì›Œë“œ,
            'year': ì—°ë„ (or None),
            'publisher': í¼ë¸”ë¦¬ì…” (or None),
            'sort': ì •ë ¬ ë°©ì‹
        }
    """
    year = extract_year(product_name)
    publisher = extract_publisher(product_name)

    # ì—°ë„ ë³´ì¡´ ì—¬ë¶€ ê²°ì •
    preserve_year = (year is not None)

    title = clean_title_for_search_enhanced(product_name, preserve_year=preserve_year)

    # í‚¤ì›Œë“œ í™•ì¥: 5ë‹¨ì–´ â†’ 10ë‹¨ì–´
    keywords = ' '.join(title.split()[:10])

    # ì •ë ¬ ë°©ì‹ ê²°ì •
    sort = 'PublishTime' if year else 'Accuracy'

    return {
        'keyword': keywords,
        'year': year,
        'publisher': publisher,
        'sort': sort
    }


def search_isbn_from_aladin_enhanced(
    product_name: str,
    crawler: AladinAPICrawler,
    max_results: int = 5
) -> Optional[str]:
    """
    ì•Œë¼ë”˜ APIë¡œ ISBN ê²€ìƒ‰ (ê°•í™” ë²„ì „)

    ê°œì„ ì‚¬í•­:
    - ìŠ¤ë§ˆíŠ¸ ì¿¼ë¦¬ ìƒì„±
    - í¼ë¸”ë¦¬ì…” í•„í„°ë§
    - ì—°ë„ ê¸°ë°˜ ì •ë ¬

    Returns:
        ISBN ë˜ëŠ” None
    """
    query = build_smart_aladin_query(product_name)

    keyword = query['keyword']
    year = query['year']
    publisher = query['publisher']
    sort = query['sort']

    if not keyword or len(keyword) < 3:
        return None

    try:
        # ì•Œë¼ë”˜ API ê²€ìƒ‰
        results = crawler.search_by_keyword(
            keyword=keyword,
            max_results=max_results,
            sort=sort
        )

        if not results:
            return None

        # í¼ë¸”ë¦¬ì…” í•„í„°ë§ (ìˆìœ¼ë©´)
        if publisher:
            for item in results:
                item_pub = item.get('publisher', '')

                # í¼ë¸”ë¦¬ì…” ë§¤ì¹­
                if publisher.lower() in item_pub.lower():
                    # ì—°ë„ ê²€ì¦ (ìˆìœ¼ë©´)
                    if year:
                        pub_date = item.get('pubDate', '')
                        if str(year) in pub_date:
                            isbn = item.get('isbn13') or item.get('isbn')
                            if isbn:
                                return isbn
                    else:
                        isbn = item.get('isbn13') or item.get('isbn')
                        if isbn:
                            return isbn

        # ì—°ë„ í•„í„°ë§ (í¼ë¸”ë¦¬ì…” ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
        if year:
            for item in results:
                pub_date = item.get('pubDate', '')
                if str(year) in pub_date:
                    isbn = item.get('isbn13') or item.get('isbn')
                    if isbn:
                        return isbn

        # ëª¨ë“  í•„í„°ë§ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
        isbn = results[0].get('isbn13') or results[0].get('isbn')
        return isbn

    except Exception as e:
        # print(f"      [ì•Œë¼ë”˜ API ì—ëŸ¬] {str(e)[:50]}")
        return None


def fill_isbn_from_aladin_enhanced(
    dry_run: bool = False,
    limit: int = None,
    db_path: str = None,
    account_id: int = None,
    api_delay: float = 1.0
):
    """
    ì•Œë¼ë”˜ APIë¡œ ISBN ì±„ìš°ê¸° (ê°•í™” ë²„ì „)

    Args:
        dry_run: Trueì¼ ê²½ìš° ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ
        limit: ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
        db_path: ì‚¬ìš©í•  DB íŒŒì¼ ê²½ë¡œ
        account_id: íŠ¹ì • ê³„ì •ë§Œ ì²˜ë¦¬ (Noneì´ë©´ ì „ì²´)
        api_delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    """
    # ì•Œë¼ë”˜ API ì´ˆê¸°í™”
    TTB_KEY = os.getenv('ALADIN_TTB_KEY')
    if not TTB_KEY:
        print('âŒ ALADIN_TTB_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
        sys.exit(1)

    crawler = AladinAPICrawler(TTB_KEY)

    # DB ì—°ê²°
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    print("=" * 80)
    print("Phase 3: ì•Œë¼ë”˜ API ê²€ìƒ‰ ê°•í™”")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN (ë¯¸ë¦¬ë³´ê¸°)' if dry_run else 'LIVE (ì‹¤ì œ ì—…ë°ì´íŠ¸)'}")
    if limit:
        print(f"ì œí•œ: ìµœëŒ€ {limit}ê°œ ë ˆì½”ë“œ")
    if account_id:
        print(f"ê³„ì • í•„í„°: account_id = {account_id}")
    print(f"API í˜¸ì¶œ ê°„ê²©: {api_delay}ì´ˆ")
    print()

    # ISBNì´ ì—†ê³  ìƒí’ˆëª…ì´ ìˆëŠ” listings ì¡°íšŒ
    query = """
        SELECT id, account_id, product_name
        FROM listings
        WHERE isbn IS NULL
          AND product_name IS NOT NULL
          AND product_name != ''
    """

    params = []
    if account_id:
        query += " AND account_id = ?"
        params.append(account_id)

    query += " ORDER BY id"

    if limit:
        query += f" LIMIT {limit}"

    cursor = conn.cursor()
    cursor.execute(query, params)
    candidates = cursor.fetchall()

    print(f"ğŸ” ëŒ€ìƒ ë ˆì½”ë“œ: {len(candidates):,}ê°œ")
    print()

    # í†µê³„
    stats = {
        'total': len(candidates),
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'with_year': 0,
        'with_publisher': 0
    }

    updated_listings = []

    start_time = time.time()

    for idx, row in enumerate(candidates, 1):
        listing_id = row[0]
        acc_id = row[1]
        product_name = row[2]

        # ì¿¼ë¦¬ ë¶„ì„
        query_info = build_smart_aladin_query(product_name)

        if query_info['year']:
            stats['with_year'] += 1
        if query_info['publisher']:
            stats['with_publisher'] += 1

        # ISBN ê²€ìƒ‰
        isbn = search_isbn_from_aladin_enhanced(product_name, crawler)

        if isbn:
            stats['success'] += 1
            updated_listings.append((listing_id, isbn, product_name))

            # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            if stats['success'] <= 5:
                print(f"âœ“ [ì„±ê³µ] {product_name[:50]}...")
                print(f"   â†’ ISBN: {isbn}")
                print(f"   â†’ ì¿¼ë¦¬: {query_info['keyword'][:60]}")
                if query_info['year']:
                    print(f"   â†’ ì—°ë„: {query_info['year']}, ì •ë ¬: {query_info['sort']}")
                if query_info['publisher']:
                    print(f"   â†’ í¼ë¸”ë¦¬ì…”: {query_info['publisher']}")
                print()
        else:
            stats['failed'] += 1

        # ì§„í–‰ ìƒí™© ì¶œë ¥ (50ê°œë§ˆë‹¤)
        if idx % 50 == 0:
            elapsed = time.time() - start_time
            rate = idx / elapsed if elapsed > 0 else 0
            remaining = (len(candidates) - idx) / rate if rate > 0 else 0

            print(f"ì§„í–‰: {idx:,}/{len(candidates):,} ({idx/len(candidates)*100:.1f}%) - "
                  f"ì„±ê³µ: {stats['success']:,}, ì‹¤íŒ¨: {stats['failed']:,} - "
                  f"ì†ë„: {rate:.1f}ê°œ/ì´ˆ, ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„")

        # API í˜¸ì¶œ ê°„ ëŒ€ê¸°
        time.sleep(api_delay)

    elapsed_total = time.time() - start_time

    print()
    print("=" * 80)
    print("ì²˜ë¦¬ ê²°ê³¼")
    print("=" * 80)
    print(f"ì´ ì²˜ë¦¬: {stats['total']:,}ê°œ")
    print(f"âœ… ì„±ê³µ: {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed']:,}ê°œ ({stats['failed']/stats['total']*100:.1f}%)")
    print()
    print(f"ğŸ“Š ì¿¼ë¦¬ ë¶„ì„:")
    print(f"   ì—°ë„ í¬í•¨: {stats['with_year']:,}ê°œ ({stats['with_year']/stats['total']*100:.1f}%)")
    print(f"   í¼ë¸”ë¦¬ì…” í¬í•¨: {stats['with_publisher']:,}ê°œ ({stats['with_publisher']/stats['total']*100:.1f}%)")
    print()
    print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed_total/60:.1f}ë¶„ ({stats['total']/elapsed_total*60:.1f}ê°œ/ë¶„)")
    print()

    # ìƒ˜í”Œ ì¶œë ¥ (ì²˜ìŒ 10ê°œ)
    if updated_listings:
        print("ğŸ“ ì¶”ì¶œ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
        print("-" * 80)
        for listing_id, isbn, product_name in updated_listings[:10]:
            print(f"ID {listing_id:5d} | ISBN: {isbn} | {product_name[:50]}")
        print()

    if not dry_run:
        # ì‹¤ì œ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")

        update_count = 0
        for listing_id, isbn, _ in updated_listings:
            try:
                cursor.execute("UPDATE listings SET isbn = ? WHERE id = ?", (isbn, listing_id))
                update_count += 1

                # 100ê°œë§ˆë‹¤ ì»¤ë°‹ (ì²´í¬í¬ì¸íŠ¸)
                if update_count % 100 == 0:
                    conn.commit()
                    print(f"   ì²´í¬í¬ì¸íŠ¸: {update_count:,}ê°œ ì»¤ë°‹ë¨")
            except Exception as e:
                print(f"âš ï¸  ID {listing_id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                conn.rollback()
                continue

        # ìµœì¢… ì»¤ë°‹
        conn.commit()
        print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_count:,}ê°œ")
    else:
        print("âš ï¸  DRY RUN ëª¨ë“œ - ë³€ê²½ì‚¬í•­ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    conn.close()

    print()
    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ì•Œë¼ë”˜ API ê²€ìƒ‰ ê°•í™”')
    parser.add_argument('--dry-run', action='store_true', help='ë³€ê²½ì‚¬í•­ì„ ì €ì¥í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')
    parser.add_argument('--limit', type=int, help='ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')
    parser.add_argument('--db', type=str, help='ì‚¬ìš©í•  DB íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: coupang_auto_backup.db)')
    parser.add_argument('--account', type=int, help='íŠ¹ì • ê³„ì •ë§Œ ì²˜ë¦¬ (account_id)')
    parser.add_argument('--delay', type=float, default=1.0, help='API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 1.0)')

    args = parser.parse_args()

    # ê¸°ë³¸ê°’ìœ¼ë¡œ backup DB ì‚¬ìš©
    db_path = args.db or 'coupang_auto_backup.db'

    try:
        stats = fill_isbn_from_aladin_enhanced(
            dry_run=args.dry_run,
            limit=args.limit,
            db_path=db_path,
            account_id=args.account,
            api_delay=args.delay
        )

        print()
        print("ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"   ì„±ê³µë¥ : {stats['success']/stats['total']*100:.1f}%")
        print(f"   ì—°ë„ í™œìš©: {stats['with_year']:,}ê°œ")
        print(f"   í¼ë¸”ë¦¬ì…” í™œìš©: {stats['with_publisher']:,}ê°œ")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
