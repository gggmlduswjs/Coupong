"""
ISBN ì—†ëŠ” ìƒí’ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ISBNì´ ì—†ëŠ” ìƒí’ˆë“¤ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ê°œì„  ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.
"""
import sys
import io
import sqlite3
from collections import Counter
import re

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def analyze_missing_isbn(db_path='coupang_auto_backup.db'):
    """ISBN ì—†ëŠ” ìƒí’ˆ ë¶„ì„"""

    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    print("=" * 80)
    print("ISBN ì—†ëŠ” ìƒí’ˆ ë¶„ì„")
    print("=" * 80)
    print()

    # ISBN ì—†ëŠ” ìƒí’ˆ ì¡°íšŒ
    cursor.execute("""
        SELECT product_name
        FROM listings
        WHERE (isbn IS NULL OR isbn = '')
        AND product_name IS NOT NULL
        LIMIT 1000
    """)

    no_isbn_products = [row[0] for row in cursor.fetchall()]

    print(f"ë¶„ì„ ëŒ€ìƒ: {len(no_isbn_products)}ê°œ ìƒ˜í”Œ")
    print()

    # 1. ì‹œë¦¬ì¦ˆ/ë¸Œëœë“œ íŒ¨í„´ ì¶”ì¶œ
    print("ğŸ“š ì£¼ìš” ì‹œë¦¬ì¦ˆ/ë¸Œëœë“œ (ìƒìœ„ 20ê°œ)")
    print("-" * 80)

    series_patterns = [
        r'^\[?([ê°€-í£a-zA-Z]+)\]',  # [ë¹„ìƒ] ë“±
        r'^([ê°€-í£a-zA-Z]+)\s+(?:ì¤‘í•™|ê³ ë“±|ì´ˆë“±)',  # "ì˜¤íˆ¬ ì¤‘í•™" ë“±
        r'(ë§ˆë”í……|ìì´ìŠ¤í† ë¦¬|ìˆ˜ëŠ¥íŠ¹ê°•|ì™„ì|í•œë|ì˜¤íˆ¬|ê°œë…í”ŒëŸ¬ìŠ¤|ì¼í’ˆ|ìˆ|ê°œë…)',  # ì£¼ìš” ë¸Œëœë“œ
    ]

    series_counter = Counter()

    for product_name in no_isbn_products:
        for pattern in series_patterns:
            match = re.search(pattern, product_name)
            if match:
                series_counter[match.group(1)] += 1
                break

    for series, count in series_counter.most_common(20):
        print(f"{series:20s}: {count:4d}ê°œ")

    print()

    # 2. í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
    print("ğŸ” ì£¼ìš” í‚¤ì›Œë“œ (ìƒìœ„ 30ê°œ)")
    print("-" * 80)

    keyword_counter = Counter()

    for product_name in no_isbn_products:
        # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        words = re.findall(r'[ê°€-í£a-zA-Z]{2,}', product_name)
        keyword_counter.update(words)

    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = {'ì„ ë¬¼', 'ì‚¬ì€í’ˆ', 'ì¦ì •', 'í¬í•¨', 'ë¬´ë£Œ', 'ì„¸íŠ¸', 'ì „', 'ê¶Œ'}

    filtered_keywords = [(k, v) for k, v in keyword_counter.most_common(50) if k not in stopwords]

    for keyword, count in filtered_keywords[:30]:
        print(f"{keyword:15s}: {count:4d}íšŒ")

    print()

    # 3. ì—°ë„ ë¶„í¬
    print("ğŸ“… ì—°ë„ ë¶„í¬")
    print("-" * 80)

    year_counter = Counter()

    for product_name in no_isbn_products:
        years = re.findall(r'20\d{2}', product_name)
        year_counter.update(years)

    for year, count in sorted(year_counter.items(), reverse=True):
        print(f"{year}: {count:4d}ê°œ")

    print()

    # 4. ìƒí’ˆëª… ê¸¸ì´ ë¶„í¬
    print("ğŸ“ ìƒí’ˆëª… ê¸¸ì´ ë¶„í¬")
    print("-" * 80)

    lengths = [len(p) for p in no_isbn_products]

    print(f"í‰ê· : {sum(lengths)/len(lengths):.1f}ì")
    print(f"ìµœì†Œ: {min(lengths)}ì")
    print(f"ìµœëŒ€: {max(lengths)}ì")
    print(f"ì¤‘ê°„ê°’: {sorted(lengths)[len(lengths)//2]}ì")

    print()

    # 5. ìƒ˜í”Œ ì¶œë ¥
    print("ğŸ“ ìƒ˜í”Œ ìƒí’ˆ (ë¬´ì‘ìœ„ 20ê°œ)")
    print("-" * 80)

    import random
    samples = random.sample(no_isbn_products, min(20, len(no_isbn_products)))

    for i, product_name in enumerate(samples, 1):
        print(f"{i:2d}. {product_name[:75]}")

    print()
    print("=" * 80)

    conn.close()


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ISBN ì—†ëŠ” ìƒí’ˆ ë¶„ì„')
    parser.add_argument('--db', type=str, default='coupang_auto_backup.db', help='DB íŒŒì¼ ê²½ë¡œ')

    args = parser.parse_args()

    try:
        analyze_missing_isbn(db_path=args.db)
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
