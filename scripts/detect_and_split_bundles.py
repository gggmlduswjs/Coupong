"""
Phase 2: ë¬¶ìŒ ìƒí’ˆ ë¶„ë¦¬ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

ë¬¶ìŒ ìƒí’ˆ íŒ¨í„´ì„ ê°ì§€í•˜ê³  ê° êµ¬ì„±í’ˆë§ˆë‹¤ ISBNì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- "A + B", "A & B", "ì„¸íŠ¸" íŒ¨í„´ ê°ì§€
- ê° êµ¬ì„±í’ˆë§ˆë‹¤ ì›Œí„°í´ ê²€ìƒ‰: Books í…Œì´ë¸” â†’ ì•Œë¼ë”˜ API
- ì„ ë¬¼/ì‚¬ì€í’ˆ ì œì™¸
- ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì €ì¥

ì˜ˆìƒ ì„±ê³¼: +400~600 ISBN (15-20ë¶„)
"""
import re
import json
import sys
import io
import os
import time
from pathlib import Path
from datetime import datetime
from typing import List, Optional, Tuple

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

import sqlite3
from crawlers.aladin_api_crawler import AladinAPICrawler


def detect_bundle(product_name: str) -> Optional[List[str]]:
    """
    ë¬¶ìŒ ìƒí’ˆ íŒ¨í„´ ê°ì§€ ë° êµ¬ì„±í’ˆ ë¶„ë¦¬

    ê°ì§€ íŒ¨í„´:
    - "A + B", "A+B"
    - "A & B", "A&B"
    - "ì„¸íŠ¸", "ì „ Nê¶Œ"

    Returns:
        êµ¬ì„±í’ˆ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None (ë‹¨ì¼ ìƒí’ˆ)
    """
    if not product_name:
        return None

    # ì„¸íŠ¸ í‚¤ì›Œë“œ í™•ì¸
    has_bundle_keyword = bool(re.search(r'ì„¸íŠ¸|ì „\s*\d+ê¶Œ', product_name))

    # + ë˜ëŠ” & êµ¬ë¶„ì í™•ì¸
    has_separator = bool(re.search(r'\s*[+&]\s*', product_name))

    if not (has_bundle_keyword or has_separator):
        return None

    # êµ¬ë¶„ìë¡œ ë¶„ë¦¬
    components = re.split(r'\s*[+&]\s*', product_name)

    if len(components) < 2:
        return None

    # ì„ ë¬¼/ì‚¬ì€í’ˆ ì œì™¸
    filtered = []
    for comp in components:
        # ì„ ë¬¼, ì‚¬ì€í’ˆ, ì¦ì • í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
        if any(kw in comp for kw in ['ì„ ë¬¼', 'ì‚¬ì€í’ˆ', 'ì¦ì •', 'í¬í•¨', 'ë¬´ë£Œ']):
            continue

        # ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸ (ë‹¨ìˆœ êµ¬ë¶„ì ì˜¤ë¥˜)
        if len(comp.strip()) < 3:
            continue

        filtered.append(comp.strip())

    # ìœ íš¨í•œ êµ¬ì„±í’ˆì´ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ë¬¶ìŒìœ¼ë¡œ ì²˜ë¦¬
    if len(filtered) >= 2:
        return filtered

    return None


def extract_keywords_for_search(component: str) -> Tuple[str, str]:
    """
    êµ¬ì„±í’ˆëª…ì—ì„œ ê²€ìƒ‰ìš© í‚¤ì›Œë“œì™€ í¼ë¸”ë¦¬ì…” ì¶”ì¶œ

    Returns:
        (keywords, publisher)
    """
    # ê´„í˜¸ ì•ˆì˜ ì¶œíŒì‚¬/ì €ì ì •ë³´ ì¶”ì¶œ
    publisher_match = re.search(r'\[(.*?)\]', component)
    if not publisher_match:
        publisher_match = re.search(r'\((.*?)\)', component)

    publisher = publisher_match.group(1) if publisher_match else ""

    # ê´„í˜¸ ì œê±°
    clean_name = re.sub(r'\[.*?\]', '', component)
    clean_name = re.sub(r'\(.*?\)', '', clean_name)

    # ì—°ë„ ì œê±°
    clean_name = re.sub(r'\d{4}ë…„?', '', clean_name)
    clean_name = re.sub(r'20\d{2}', '', clean_name)

    # ê¶Œìˆ˜ ì œê±°
    clean_name = re.sub(r'\d+ê¶Œ', '', clean_name)

    # ì„¸íŠ¸ ì œê±°
    clean_name = re.sub(r'ì„¸íŠ¸\d*', '', clean_name)

    # ê³µë°± ì •ë¦¬
    clean_name = ' '.join(clean_name.split())

    return clean_name.strip(), publisher.strip()


def search_isbn_from_books(component: str, conn) -> Optional[str]:
    """
    Books í…Œì´ë¸”ì—ì„œ ISBN ê²€ìƒ‰ (ì¦‰ì‹œ)

    Returns:
        ISBN ë˜ëŠ” None
    """
    keywords, publisher = extract_keywords_for_search(component)

    # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if len(keywords) < 3:
        return None

    try:
        cursor = conn.cursor()

        # 1ë‹¨ê³„: í‚¤ì›Œë“œ + í¼ë¸”ë¦¬ì…” ë§¤ì¹­
        if publisher:
            cursor.execute("""
                SELECT DISTINCT b.isbn
                FROM books b
                LEFT JOIN publishers pub ON b.publisher_id = pub.id
                WHERE LOWER(b.title) LIKE ? AND LOWER(pub.name) LIKE ?
                LIMIT 1
            """, (f'%{keywords.lower()[:40]}%', f'%{publisher.lower()}%'))

            row = cursor.fetchone()
            if row:
                return row[0]

        # 2ë‹¨ê³„: í‚¤ì›Œë“œë§Œ ë§¤ì¹­
        cursor.execute("""
            SELECT DISTINCT isbn
            FROM books
            WHERE LOWER(title) LIKE ?
            LIMIT 1
        """, (f'%{keywords.lower()[:40]}%',))

        row = cursor.fetchone()
        if row:
            return row[0]

    except Exception as e:
        print(f"      [Books í…Œì´ë¸” ê²€ìƒ‰ ì—ëŸ¬] {str(e)[:50]}")

    return None


def search_isbn_from_aladin(component: str, crawler: AladinAPICrawler) -> Optional[str]:
    """
    ì•Œë¼ë”˜ APIì—ì„œ ISBN ê²€ìƒ‰ (1ì´ˆ ëŒ€ê¸°)

    Returns:
        ISBN ë˜ëŠ” None
    """
    keywords, publisher = extract_keywords_for_search(component)

    # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if len(keywords) < 3:
        return None

    try:
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¤€ë¹„ (ì• 5ë‹¨ì–´)
        search_words = ' '.join(keywords.split()[:5])

        # ì•Œë¼ë”˜ API ê²€ìƒ‰
        results = crawler.search_by_keyword(
            keyword=search_words,
            max_results=3,
            sort="Accuracy"
        )

        if not results:
            return None

        # í¼ë¸”ë¦¬ì…” í•„í„°ë§
        if publisher:
            for item in results:
                item_pub = item.get('publisher', '')
                if publisher.lower() in item_pub.lower():
                    isbn = item.get('isbn13') or item.get('isbn')
                    if isbn:
                        return isbn

        # í¼ë¸”ë¦¬ì…” ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
        isbn = results[0].get('isbn13') or results[0].get('isbn')
        return isbn

    except Exception as e:
        print(f"      [ì•Œë¼ë”˜ API ì—ëŸ¬] {str(e)[:50]}")

    return None


def process_bundle(product_name: str, conn, crawler: AladinAPICrawler, verbose: bool = False) -> Optional[str]:
    """
    ë¬¶ìŒ ìƒí’ˆì„ ì²˜ë¦¬í•˜ì—¬ ëª¨ë“  êµ¬ì„±í’ˆì˜ ISBN ì¶”ì¶œ

    Returns:
        ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ISBN ë¬¸ìì—´ ë˜ëŠ” None
    """
    components = detect_bundle(product_name)

    if not components:
        return None

    if verbose:
        print(f"   ë¬¶ìŒ ê°ì§€: {len(components)}ê°œ êµ¬ì„±í’ˆ")
        for i, comp in enumerate(components, 1):
            print(f"      [{i}] {comp[:60]}")

    isbns = []

    for i, comp in enumerate(components, 1):
        if verbose:
            print(f"      [{i}/{len(components)}] ê²€ìƒ‰ ì¤‘...", end=' ')

        # Books í…Œì´ë¸” ê²€ìƒ‰ (ì¦‰ì‹œ, ì•Œë¼ë”˜ APIëŠ” ì„¸íŠ¸ ìƒí’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰ ì‹œ ê²°ê³¼ ì—†ìŒ)
        isbn = search_isbn_from_books(comp, conn)

        if isbn:
            if verbose:
                print(f"âœ“ Books í…Œì´ë¸”ì—ì„œ ë°œê²¬: {isbn}")
            isbns.append(isbn)
        else:
            if verbose:
                print("âœ— ë°œê²¬ ëª»í•¨")

    if isbns:
        return ','.join(isbns)

    return None


def detect_and_split_bundles(dry_run: bool = False, limit: int = None, db_path: str = None, verbose: bool = False):
    """
    ë¬¶ìŒ ìƒí’ˆì„ ê°ì§€í•˜ê³  ê° êµ¬ì„±í’ˆì˜ ISBNì„ ê²€ìƒ‰í•˜ì—¬ ì—…ë°ì´íŠ¸

    Args:
        dry_run: Trueì¼ ê²½ìš° ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ
        limit: ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
        db_path: ì‚¬ìš©í•  DB íŒŒì¼ ê²½ë¡œ
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥
    """
    # ì•Œë¼ë”˜ API ì´ˆê¸°í™”
    TTB_KEY = os.getenv('ALADIN_TTB_KEY')
    if not TTB_KEY:
        print('âŒ ALADIN_TTB_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
        sys.exit(1)

    crawler = AladinAPICrawler(TTB_KEY)

    # DB ì—°ê²°
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    print("=" * 80)
    print("Phase 2: ë¬¶ìŒ ìƒí’ˆ ë¶„ë¦¬ ì²˜ë¦¬")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN (ë¯¸ë¦¬ë³´ê¸°)' if dry_run else 'LIVE (ì‹¤ì œ ì—…ë°ì´íŠ¸)'}")
    if limit:
        print(f"ì œí•œ: ìµœëŒ€ {limit}ê°œ ë ˆì½”ë“œ")
    print()

    # ISBNì´ ì—†ê³  ë¬¶ìŒ íŒ¨í„´ì´ ìˆëŠ” listings ì¡°íšŒ
    query = """
        SELECT id, product_name
        FROM listings
        WHERE (isbn IS NULL OR isbn = '')
          AND product_name IS NOT NULL
          AND product_name != ''
          AND (
              product_name LIKE '%+%'
              OR product_name LIKE '%&%'
              OR product_name LIKE '%ì„¸íŠ¸%'
              OR product_name LIKE '%ì „%ê¶Œ%'
          )
    """

    if limit:
        query += f" LIMIT {limit}"

    cursor = conn.cursor()
    cursor.execute(query)
    candidates = cursor.fetchall()

    print(f"ğŸ“¦ ëŒ€ìƒ ë ˆì½”ë“œ: {len(candidates):,}ê°œ (ë¬¶ìŒ íŒ¨í„´ í¬í•¨)")
    print()

    # í†µê³„
    stats = {
        'total': len(candidates),
        'bundle_detected': 0,
        'isbn_found': 0,
        'isbn_not_found': 0,
        'not_bundle': 0
    }

    updated_listings = []

    for idx, row in enumerate(candidates, 1):
        listing_id = row[0]
        product_name = row[1]

        if verbose or (idx <= 5):  # ì²˜ìŒ 5ê°œëŠ” í•­ìƒ ì¶œë ¥
            print(f"[{idx}/{len(candidates)}] ID {listing_id}: {product_name[:70]}")

        # ë¬¶ìŒ ì²˜ë¦¬
        isbn_str = process_bundle(product_name, conn, crawler, verbose=(verbose or idx <= 5))

        if isbn_str:
            stats['bundle_detected'] += 1
            stats['isbn_found'] += 1
            updated_listings.append((listing_id, isbn_str, product_name))

            if not verbose and idx > 5:
                # ì§„í–‰ ìƒí™© ê°„ë‹¨íˆ í‘œì‹œ (10ê°œë§ˆë‹¤)
                if idx % 10 == 0:
                    print(f"âœ“ ì§„í–‰: {idx:,}/{len(candidates):,} ({idx/len(candidates)*100:.1f}%) - ì„±ê³µ: {stats['isbn_found']:,}")
        else:
            # ë¬¶ìŒ íŒ¨í„´ì€ ìˆì§€ë§Œ ISBNì„ ì°¾ì§€ ëª»í•¨
            components = detect_bundle(product_name)
            if components:
                stats['bundle_detected'] += 1
                stats['isbn_not_found'] += 1
            else:
                stats['not_bundle'] += 1

    print()
    print("=" * 80)
    print("ì²˜ë¦¬ ê²°ê³¼")
    print("=" * 80)
    print(f"ì´ ì²˜ë¦¬: {stats['total']:,}ê°œ")
    print(f"ğŸ“¦ ë¬¶ìŒ ê°ì§€: {stats['bundle_detected']:,}ê°œ ({stats['bundle_detected']/stats['total']*100:.1f}%)")
    print(f"âœ… ISBN ë°œê²¬: {stats['isbn_found']:,}ê°œ ({stats['isbn_found']/stats['bundle_detected']*100:.1f}% of bundles)")
    print(f"âŒ ISBN ì—†ìŒ: {stats['isbn_not_found']:,}ê°œ")
    print(f"âš ï¸  ë‹¨ì¼ ìƒí’ˆ: {stats['not_bundle']:,}ê°œ (ë¬¶ìŒ ì•„ë‹˜)")
    print()

    # ìƒ˜í”Œ ì¶œë ¥ (ì²˜ìŒ 10ê°œ)
    if updated_listings:
        print("ğŸ“ ì¶”ì¶œ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
        print("-" * 80)
        for listing_id, isbn, product_name in updated_listings[:10]:
            isbn_count = len(isbn.split(','))
            print(f"ID {listing_id:5d} | ISBN ({isbn_count}ê°œ): {isbn[:40]:40s} | {product_name[:35]}")
        print()

    if not dry_run:
        # ì‹¤ì œ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")

        update_count = 0
        for listing_id, isbn_str, _ in updated_listings:
            try:
                cursor.execute("UPDATE listings SET isbn = ? WHERE id = ?", (isbn_str, listing_id))
                update_count += 1

                # 50ê°œë§ˆë‹¤ ì»¤ë°‹ (ì²´í¬í¬ì¸íŠ¸)
                if update_count % 50 == 0:
                    conn.commit()
                    print(f"   ì²´í¬í¬ì¸íŠ¸: {update_count:,}ê°œ ì»¤ë°‹ë¨")
            except Exception as e:
                print(f"âš ï¸  ID {listing_id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                conn.rollback()
                continue

        # ìµœì¢… ì»¤ë°‹
        conn.commit()
        print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_count:,}ê°œ")
    else:
        print("âš ï¸  DRY RUN ëª¨ë“œ - ë³€ê²½ì‚¬í•­ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    conn.close()

    print()
    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ë¬¶ìŒ ìƒí’ˆ ë¶„ë¦¬ ì²˜ë¦¬')
    parser.add_argument('--dry-run', action='store_true', help='ë³€ê²½ì‚¬í•­ì„ ì €ì¥í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')
    parser.add_argument('--limit', type=int, help='ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')
    parser.add_argument('--db', type=str, help='ì‚¬ìš©í•  DB íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: coupang_auto_backup.db)')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥')

    args = parser.parse_args()

    # ê¸°ë³¸ê°’ìœ¼ë¡œ backup DB ì‚¬ìš©
    db_path = args.db or 'coupang_auto.db'

    try:
        stats = detect_and_split_bundles(
            dry_run=args.dry_run,
            limit=args.limit,
            db_path=db_path,
            verbose=args.verbose
        )

        print()
        print("ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"   ë¬¶ìŒ ê°ì§€ìœ¨: {stats['bundle_detected']/stats['total']*100:.1f}%")
        print(f"   ISBN ë°œê²¬ìœ¨: {stats['isbn_found']/stats['bundle_detected']*100:.1f}% (ë¬¶ìŒ ì¤‘)")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
