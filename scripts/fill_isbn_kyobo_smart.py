#!/usr/bin/env python3
"""
êµë³´ë¬¸ê³  ìŠ¤ë§ˆíŠ¸ í¬ë¡¤ë§ - ì¤‘ë³µ ì œê±° ë° ê²°ê³¼ ê³µìœ 

1. ìœ ë‹ˆí¬í•œ ìƒí’ˆëª…ë§Œ í¬ë¡¤ë§ (ì¤‘ë³µ ì œê±°)
2. ì°¾ì€ ISBNì„ ìƒí’ˆëª… ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ê³„ì •ì— ì ìš©

ì‚¬ìš©ë²•:
  python scripts/fill_isbn_kyobo_smart.py [--limit N] [--delay S]
"""

import re
import sys
import time
import argparse
from pathlib import Path
from urllib.parse import quote
import io
from collections import defaultdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

# Windows cp949 ì¸ì½”ë”© ëŒ€ì‘
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")

try:
    import requests
except ImportError:
    print("âŒ pip install requests í•„ìš”")
    sys.exit(1)

from sqlalchemy import text
from app.database import engine

KYOBO_SEARCH = "https://search.kyobobook.co.kr/search"
KYOBO_DETAIL = "https://product.kyobobook.co.kr/detail"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8",
    "Referer": "https://search.kyobobook.co.kr/",
}

# ìƒí’ˆëª… ì •ì œ íŒ¨í„´
NOISE_PATTERNS = [
    (r"\+\s*ì‚¬ì€í’ˆ", ""),
    (r"\+\s*ì„ ë¬¼", ""),
    (r"ì‚¬ì€í’ˆ\s*ì¦ì •\)?", ""),
    (r"ì„ ë¬¼\s*\+", ""),
    (r"\(\s*ì„ ë¬¼\s*\)", ""),
    (r"\(\s*ì‚¬ì€í’ˆì¦ì •\s*\)", ""),
    (r"ì‚¬ì€í’ˆ\s*\+", ""),
    (r"\*+", ""),
    (r"\#\w+", ""),
    (r"\([^)]*\)", ""),  # ëª¨ë“  ê´„í˜¸ ì œê±°
]


def normalize_product_name(name: str) -> str:
    """ìƒí’ˆëª… ì •ê·œí™” (ë§¤ì¹­ìš©)"""
    s = name.lower().strip()
    for pat, repl in NOISE_PATTERNS:
        s = re.sub(pat, repl, s, flags=re.IGNORECASE)
    s = re.sub(r"\s+", " ", s).strip()
    return s


def clean_for_search(name: str) -> str:
    """ê²€ìƒ‰ìš© ìƒí’ˆëª… ì •ì œ"""
    s = name.strip()
    for pat, repl in NOISE_PATTERNS:
        s = re.sub(pat, repl, s, flags=re.IGNORECASE)
    s = re.sub(r"\s+", " ", s).strip()
    # ì„¸íŠ¸ ìƒí’ˆì€ ì²« ë²ˆì§¸ í•­ëª©ë§Œ
    if "+" in s or "&" in s or "ì„¸íŠ¸" in s:
        parts = re.split(r"\s*[+&]\s*", s)
        s = parts[0].replace("ì„¸íŠ¸", "").strip()
    return s[:50]


def search_kyobo(keyword: str) -> list[str]:
    """êµë³´ ê²€ìƒ‰ â†’ ìƒí’ˆ ìƒì„¸ ID ëª©ë¡ ë°˜í™˜"""
    url = f"{KYOBO_SEARCH}?keyword={quote(keyword)}&target=total"
    try:
        r = requests.get(url, headers=HEADERS, timeout=15)
        r.raise_for_status()
        html = r.text
        ids = re.findall(r"product\.kyobobook\.co\.kr/detail/(S\d+)", html)
        if not ids:
            ids = re.findall(r"/detail/(S\d+)", html)
        return list(dict.fromkeys(ids))[:3]
    except:
        return []


def fetch_isbn_from_detail(prod_id: str) -> str | None:
    """ìƒì„¸í˜ì´ì§€ì—ì„œ ISBN ì¶”ì¶œ"""
    url = f"{KYOBO_DETAIL}/{prod_id}"
    try:
        r = requests.get(url, headers=HEADERS, timeout=15, allow_redirects=True)
        r.raise_for_status()
        html = r.content.decode(r.encoding or "utf-8", errors="replace")

        # ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
        patterns = [
            r"\|\s*ISBN\s*\|\s*(\d{13})\s*\|",
            r"ISBN[\s:]*(\d{13})",
            r"/pdt/(97[89]\d{10})\.",
            r"(97[89]\d{10})",
        ]

        for pat in patterns:
            m = re.search(pat, html, re.I)
            if m:
                return m.group(1)
    except:
        pass
    return None


def get_unique_products(limit: int = 0):
    """ìœ ë‹ˆí¬í•œ ìƒí’ˆëª…ë§Œ ì¡°íšŒ (ì¤‘ë³µ ì œê±°)"""
    conn = engine.connect()

    # ISBN ì—†ëŠ” ëª¨ë“  ìƒí’ˆ ì¡°íšŒ
    query = text("""
        SELECT id, account_id, product_name
        FROM listings
        WHERE (isbn IS NULL OR isbn = '')
        AND product_name IS NOT NULL
        AND product_name != ''
        ORDER BY id
    """)

    all_products = conn.execute(query).fetchall()
    conn.close()

    # ìƒí’ˆëª…ìœ¼ë¡œ ê·¸ë£¹í™” (ì •ê·œí™”ëœ ì´ë¦„ ê¸°ì¤€)
    by_normalized_name = defaultdict(list)
    for listing_id, account_id, product_name in all_products:
        normalized = normalize_product_name(product_name)
        if len(normalized) >= 6:
            by_normalized_name[normalized].append({
                'id': listing_id,
                'account_id': account_id,
                'product_name': product_name,
                'normalized': normalized
            })

    # ê° ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ìƒí’ˆ 1ê°œì”©ë§Œ ì„ íƒ
    unique_products = []
    for normalized, group in by_normalized_name.items():
        # ì²« ë²ˆì§¸ ìƒí’ˆì„ ëŒ€í‘œë¡œ ì„ íƒ
        unique_products.append({
            'representative': group[0],
            'group_size': len(group),
            'all_items': group
        })

    if limit > 0:
        unique_products = unique_products[:limit]

    print(f"ì „ì²´ ìƒí’ˆ: {len(all_products):,}ê°œ")
    print(f"ìœ ë‹ˆí¬ ìƒí’ˆëª…: {len(unique_products):,}ê°œ (ì¤‘ë³µ ì œê±°)")
    print()

    return unique_products


def update_all_accounts(normalized_name: str, isbn: str, all_items: list) -> dict:
    """ì°¾ì€ ISBNì„ í•´ë‹¹ ìƒí’ˆëª…ì˜ ëª¨ë“  ê³„ì •ì— ì—…ë°ì´íŠ¸"""
    conn = engine.connect()

    stats = {'success': 0, 'duplicate': 0, 'error': 0}

    for item in all_items:
        try:
            update_query = text("UPDATE listings SET isbn = :isbn WHERE id = :lid")
            conn.execute(update_query, {'isbn': isbn, 'lid': item['id']})
            stats['success'] += 1
        except Exception as e:
            stats['error'] += 1

    conn.commit()
    conn.close()
    return stats


def main():
    parser = argparse.ArgumentParser(description="êµë³´ë¬¸ê³  ìŠ¤ë§ˆíŠ¸ í¬ë¡¤ë§ (ì¤‘ë³µ ì œê±°)")
    parser.add_argument("--limit", type=int, default=0, help="ì²˜ë¦¬ ìƒí’ˆ ìˆ˜ (0=ì „ì²´)")
    parser.add_argument("--delay", type=float, default=1.5, help="ìš”ì²­ ê°„ ëŒ€ê¸°(ì´ˆ)")
    args = parser.parse_args()

    print("=" * 80)
    print("êµë³´ë¬¸ê³  ìŠ¤ë§ˆíŠ¸ í¬ë¡¤ë§ (ì¤‘ë³µ ì œê±° + ê²°ê³¼ ê³µìœ )")
    print("=" * 80)
    print()

    unique_products = get_unique_products(args.limit)

    total_stats = {
        'crawled': 0,
        'found': 0,
        'not_found': 0,
        'total_updated': 0,
        'total_duplicate': 0,
    }

    for i, item in enumerate(unique_products, 1):
        rep = item['representative']
        group_size = item['group_size']

        search_query = clean_for_search(rep['product_name'])

        if len(search_query) < 6:
            print(f"[{i}/{len(unique_products)}] â­ï¸  ë„ˆë¬´ ì§§ìŒ (ê·¸ë£¹: {group_size}ê°œ)")
            total_stats['not_found'] += 1
            continue

        print(f"[{i}/{len(unique_products)}] {search_query[:50]}... (ê·¸ë£¹: {group_size}ê°œ)")

        # êµë³´ë¬¸ê³  ê²€ìƒ‰
        prod_ids = search_kyobo(search_query)
        time.sleep(args.delay)

        if not prod_ids:
            print(f"    â†’ âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            total_stats['not_found'] += 1
            continue

        # ìƒì„¸ í˜ì´ì§€ì—ì„œ ISBN ì¶”ì¶œ
        found_isbn = None
        for pid in prod_ids:
            isbn = fetch_isbn_from_detail(pid)
            time.sleep(args.delay)
            if isbn:
                found_isbn = isbn
                break

        if not found_isbn:
            print(f"    â†’ âŒ ISBN ì—†ìŒ")
            total_stats['not_found'] += 1
            continue

        total_stats['crawled'] += 1
        total_stats['found'] += 1

        # ëª¨ë“  ê³„ì •ì— ì—…ë°ì´íŠ¸
        update_stats = update_all_accounts(rep['normalized'], found_isbn, item['all_items'])
        total_stats['total_updated'] += update_stats['success']
        total_stats['total_duplicate'] += update_stats['duplicate']

        print(f"    â†’ âœ… ISBN {found_isbn}")
        print(f"       ì—…ë°ì´íŠ¸: {update_stats['success']}ê°œ, ì¤‘ë³µ: {update_stats['duplicate']}ê°œ")

        # 100ê°œë§ˆë‹¤ í†µê³„
        if i % 100 == 0:
            print()
            print(f"ì§„í–‰: {i}/{len(unique_products)} - ë°œê²¬: {total_stats['found']}, ì—…ë°ì´íŠ¸: {total_stats['total_updated']}")
            print()

    print()
    print("=" * 80)
    print("ì™„ë£Œ")
    print("=" * 80)
    print(f"í¬ë¡¤ë§ ëŒ€ìƒ: {len(unique_products):,}ê°œ (ìœ ë‹ˆí¬)")
    print(f"âœ… ISBN ë°œê²¬: {total_stats['found']:,}ê°œ")
    print(f"ğŸ“ ì´ ì—…ë°ì´íŠ¸: {total_stats['total_updated']:,}ê°œ")
    print(f"âš ï¸  ì¤‘ë³µ: {total_stats['total_duplicate']:,}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {total_stats['not_found']:,}ê°œ")
    print("=" * 80)


if __name__ == "__main__":
    main()
