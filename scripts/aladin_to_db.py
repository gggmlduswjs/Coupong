"""ì•Œë¼ë”˜ API â†’ DB ì €ì¥ â†’ CSV ìƒì„±"""
import sys
from pathlib import Path
import os

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from crawlers.aladin_api_crawler import AladinAPICrawler
from app.database import SessionLocal
from app.models.kyobo_product import KyoboProduct
from app.models.account import Account
from uploaders.coupang_csv_generator import CoupangCSVGenerator
from datetime import datetime


def main():
    """ì•Œë¼ë”˜ APIë¡œ ë„ì„œ ê²€ìƒ‰ â†’ DB ì €ì¥ â†’ CSV ìƒì„±"""

    print("\n" + "ğŸš€ "*30)
    print("ì•Œë¼ë”˜ API â†’ ì¿ íŒ¡ CSV ìë™ ìƒì„±")
    print("ğŸš€ "*30)

    # TTBKey í™•ì¸
    ttb_key = os.getenv("ALADIN_TTB_KEY")

    if not ttb_key:
        print("\nâš ï¸  ì•Œë¼ë”˜ TTBKeyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("\në°œê¸‰ ë°©ë²•:")
        print("1. https://www.aladin.co.kr/ttb/wblog_manage.aspx ì ‘ì†")
        print("2. ì•Œë¼ë”˜ ë¡œê·¸ì¸")
        print("3. TTB í‚¤ ë°œê¸‰")
        print("4. .env íŒŒì¼ì— ì¶”ê°€: ALADIN_TTB_KEY=your_key")
        print()

        ttb_key = input("TTBKeyë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë˜ëŠ” Enter=ì¢…ë£Œ): ").strip()

        if not ttb_key:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = AladinAPICrawler(ttb_key=ttb_key)

    # ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥
    print("\n" + "="*60)
    print("ê²€ìƒ‰ ì„¤ì •")
    print("="*60)

    keyword = input("\nê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: ì´ˆë“±ìˆ˜í•™): ").strip() or "ì´ˆë“±êµì¬"

    max_results_input = input("ìµœëŒ€ ê²€ìƒ‰ ê°œìˆ˜ (ê¸°ë³¸ 20): ").strip()
    try:
        max_results = int(max_results_input) if max_results_input else 20
    except:
        max_results = 20

    # ê²€ìƒ‰
    print("\n" + "="*60)
    print(f"ì•Œë¼ë”˜ API ê²€ìƒ‰: '{keyword}'")
    print("="*60)

    products = crawler.search_by_keyword(keyword, max_results=max_results)

    if not products:
        print("\nê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nâœ… ê²€ìƒ‰ ì™„ë£Œ: {len(products)}ê°œ")

    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    print("\n" + "="*60)
    print("ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
    print("="*60)

    for i, p in enumerate(products[:5], 1):
        print(f"\n{i}. {p['title'][:50]}")
        print(f"   ì €ì: {p['author']}")
        print(f"   ì¶œíŒì‚¬: {p['publisher']}")
        print(f"   ê°€ê²©: {p['original_price']:,}ì›")

    if len(products) > 5:
        print(f"\n... ì™¸ {len(products) - 5}ê°œ")

    # í™•ì¸
    proceed = input("\n\nDBì— ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()

    if proceed != 'y':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    # DB ì €ì¥
    save_to_db(products)

    # CSV ìƒì„±
    generate_csvs(products)


def save_to_db(products):
    """DBì— ì €ì¥"""
    print("\n" + "="*60)
    print("ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥")
    print("="*60)

    db = SessionLocal()
    saved = 0
    skipped = 0

    try:
        for product in products:
            # ISBNì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if not product.get("isbn"):
                skipped += 1
                continue

            # ì¤‘ë³µ ì²´í¬
            existing = db.query(KyoboProduct).filter(
                KyoboProduct.isbn == product["isbn"]
            ).first()

            if existing:
                print(f"â­ï¸  ì´ë¯¸ ì¡´ì¬: {product['title'][:40]}")
                skipped += 1
                continue

            # ì €ì¥
            kyobo_product = KyoboProduct(
                isbn=product["isbn"],
                title=product["title"],
                author=product["author"],
                publisher=product["publisher"],
                original_price=product["original_price"],
                category=product["category"],
                subcategory=product["subcategory"],
                image_url=product["image_url"],
                description=product["description"],
                kyobo_url=product["kyobo_url"],
                publish_date=product["publish_date"],
                crawled_at=datetime.utcnow(),
                is_processed=False
            )

            db.add(kyobo_product)
            saved += 1
            print(f"âœ“ ì €ì¥: {product['title'][:40]}")

        db.commit()

        print(f"\nâœ… DB ì €ì¥ ì™„ë£Œ!")
        print(f"   ì €ì¥: {saved}ê°œ")
        print(f"   ê±´ë„ˆëœ€: {skipped}ê°œ")

    except Exception as e:
        print(f"\nâŒ DB ì €ì¥ ì˜¤ë¥˜: {e}")
        db.rollback()

    finally:
        db.close()


def generate_csvs(products):
    """CSV ìƒì„±"""
    print("\n" + "="*60)
    print("ì¿ íŒ¡ CSV ìƒì„±")
    print("="*60)

    # ê³„ì • ì¡°íšŒ
    db = SessionLocal()
    accounts = db.query(Account).filter(Account.is_active == True).all()

    if accounts:
        account_names = [acc.account_name for acc in accounts]
    else:
        account_names = ["account_1", "account_2", "account_3", "account_4", "account_5"]

    db.close()

    # ìƒí’ˆ ë°ì´í„° ë³€í™˜
    product_data = []
    for p in products:
        if not p.get("isbn"):  # ISBN ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            continue

        sale_price = int(p["original_price"] * 0.9)
        product_data.append({
            "product_name": p["title"],
            "original_price": p["original_price"],
            "sale_price": sale_price,
            "isbn": p["isbn"],
            "publisher": p["publisher"],
            "author": p["author"],
            "main_image_url": p["image_url"],
            "description": p["description"] or "ìƒì„¸í˜ì´ì§€ ì°¸ì¡°"
        })

    if not product_data:
        print("\nìƒì„±í•  ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # CSV ìƒì„±
    generator = CoupangCSVGenerator()
    result = generator.generate_batch_csvs(product_data, account_names)

    print(f"\nâœ… CSV ìƒì„± ì™„ë£Œ:")
    for account, filepath in result.items():
        print(f"   {account}: {filepath}")

    print("\n" + "="*60)
    print("ì™„ë£Œ!")
    print("="*60)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("1. data/uploads/ í´ë” í™•ì¸")
    print("2. ì¿ íŒ¡ íŒë§¤ìì„¼í„° > ìƒí’ˆê´€ë¦¬ > ì¼ê´„ë“±ë¡")
    print("3. CSV íŒŒì¼ ì—…ë¡œë“œ")
    print()


if __name__ == "__main__":
    main()
