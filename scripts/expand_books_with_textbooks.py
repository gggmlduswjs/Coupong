"""
Books í…Œì´ë¸” í™•ì¥ - ì£¼ìš” êµì¬ ì‹œë¦¬ì¦ˆ í¬ë¡¤ë§

ì£¼ìš” êµì¬ ì‹œë¦¬ì¦ˆë¥¼ ì•Œë¼ë”˜ APIë¡œ í¬ë¡¤ë§í•˜ì—¬ Books í…Œì´ë¸”ì— ì¶”ê°€í•©ë‹ˆë‹¤.
- ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì£¼ìš” ì‹œë¦¬ì¦ˆ 20ê°œ
- ì‹œë¦¬ì¦ˆë³„ ì „ì²´ ìƒí’ˆ í¬ë¡¤ë§
- ì¤‘ë³µ ì œê±° í›„ Books ì¶”ê°€
"""
import sys
import io
import os
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

import sqlite3
from crawlers.aladin_api_crawler import AladinAPICrawler


# ì£¼ìš” êµì¬ ì‹œë¦¬ì¦ˆ (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
MAJOR_TEXTBOOK_SERIES = [
    # ê³ ë“± ìˆ˜í•™/ê³¼í•™
    ('ê°œë…ì›ë¦¬', ['ìˆ˜í•™', 'ë¬¼ë¦¬', 'í™”í•™']),
    ('ìˆ', ['ìˆ˜í•™']),
    ('ìì´ìŠ¤í† ë¦¬', ['ìˆ˜í•™', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒëª…ê³¼í•™', 'ì§€êµ¬ê³¼í•™']),
    ('ë§ˆë”í……', ['ìˆ˜í•™', 'ì˜ì–´', 'êµ­ì–´', 'ê³¼í•™']),
    ('ì™„ì', ['ìˆ˜í•™', 'ê³¼í•™', 'ì‚¬íšŒ']),
    ('ì˜¤íˆ¬', ['ê³¼í•™']),
    ('í’ì‚°ì', ['ìˆ˜í•™']),
    ('ì¼í’ˆ', ['ìˆ˜í•™', 'ê³¼í•™']),

    # ì¤‘ë“±
    ('í•œë', ['ìˆ˜í•™', 'ê³¼í•™', 'ì‚¬íšŒ', 'ì—­ì‚¬']),
    ('ë‚´ì‹ ì½˜ì„œíŠ¸', ['ì˜ì–´', 'ìˆ˜í•™', 'êµ­ì–´']),

    # ìˆ˜ëŠ¥
    ('ìˆ˜ëŠ¥íŠ¹ê°•', ['êµ­ì–´', 'ì˜ì–´', 'ìˆ˜í•™', 'ì‚¬íšŒ', 'ê³¼í•™']),
    ('ìˆ˜ëŠ¥ì™„ì„±', ['êµ­ì–´', 'ì˜ì–´', 'ìˆ˜í•™']),
    ('EBS', ['êµ­ì–´', 'ì˜ì–´', 'ìˆ˜í•™']),

    # ì´ˆë“±
    ('ë””ë”¤ëŒ', ['ìˆ˜í•™']),
    ('ìš°ë“±ìƒ', ['ìˆ˜í•™', 'ê³¼í•™']),
    ('ìµœìƒìœ„', ['ìˆ˜í•™']),
]


def search_textbook_series(
    crawler: AladinAPICrawler,
    series_name: str,
    subjects: List[str],
    max_per_query: int = 50
) -> List[Dict]:
    """
    íŠ¹ì • ì‹œë¦¬ì¦ˆì˜ êµì¬ë¥¼ ì•Œë¼ë”˜ì—ì„œ ê²€ìƒ‰

    Args:
        crawler: ì•Œë¼ë”˜ í¬ë¡¤ëŸ¬
        series_name: ì‹œë¦¬ì¦ˆëª… (ì˜ˆ: "ì˜¤íˆ¬")
        subjects: ê³¼ëª© ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ìˆ˜í•™", "ê³¼í•™"])
        max_per_query: ì¿¼ë¦¬ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜

    Returns:
        ë„ì„œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    all_books = []

    # ì‹œë¦¬ì¦ˆëª…ë§Œìœ¼ë¡œ ê²€ìƒ‰
    try:
        print(f"  ê²€ìƒ‰: {series_name}")
        results = crawler.search_by_keyword(
            keyword=series_name,
            max_results=max_per_query,
            sort='PublishTime'  # ìµœì‹ ìˆœ
        )

        if results:
            print(f"    â†’ {len(results)}ê°œ ë°œê²¬")
            all_books.extend(results)

        time.sleep(0.5)  # API ì œí•œ
    except Exception as e:
        print(f"    [ì—ëŸ¬] {str(e)[:50]}")

    # ì‹œë¦¬ì¦ˆëª… + ê³¼ëª©ìœ¼ë¡œ ê²€ìƒ‰
    for subject in subjects:
        try:
            keyword = f"{series_name} {subject}"
            print(f"  ê²€ìƒ‰: {keyword}")

            results = crawler.search_by_keyword(
                keyword=keyword,
                max_results=max_per_query,
                sort='PublishTime'
            )

            if results:
                print(f"    â†’ {len(results)}ê°œ ë°œê²¬")
                all_books.extend(results)

            time.sleep(0.5)  # API ì œí•œ
        except Exception as e:
            print(f"    [ì—ëŸ¬] {str(e)[:50]}")

    return all_books


def extract_book_info(aladin_item: Dict) -> Dict:
    """
    ì•Œë¼ë”˜ API ê²°ê³¼ì—ì„œ Book ì •ë³´ ì¶”ì¶œ

    Returns:
        {
            'isbn': ISBN-13,
            'title': ì œëª©,
            'author': ì €ì,
            'publisher_name': ì¶œíŒì‚¬,
            'year': ì¶œíŒì—°ë„,
            'list_price': ì •ê°€
        }
    """
    isbn = aladin_item.get('isbn13') or aladin_item.get('isbn')

    # pubDateì—ì„œ ì—°ë„ ì¶”ì¶œ
    pub_date = aladin_item.get('pubDate', '')
    year = None
    if pub_date:
        try:
            year = int(pub_date[:4])
        except:
            pass

    return {
        'isbn': isbn,
        'title': aladin_item.get('title', ''),
        'author': aladin_item.get('author', ''),
        'publisher_name': aladin_item.get('publisher', ''),
        'year': year,
        'list_price': aladin_item.get('priceStandard', 0)
    }


def insert_books_to_db(books: List[Dict], conn, dry_run: bool = False) -> tuple:
    """
    Books í…Œì´ë¸”ì— ë„ì„œ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)

    Returns:
        (ì¶”ê°€ëœ ìˆ˜, ì¤‘ë³µ ìˆ˜)
    """
    cursor = conn.cursor()

    added = 0
    duplicates = 0

    for book in books:
        isbn = book['isbn']

        if not isbn:
            continue

        # ì¤‘ë³µ ì²´í¬
        cursor.execute("SELECT COUNT(*) FROM books WHERE isbn = ?", (isbn,))
        if cursor.fetchone()[0] > 0:
            duplicates += 1
            continue

        if not dry_run:
            try:
                cursor.execute("""
                    INSERT INTO books (isbn, title, author, publisher_name, year, list_price, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    book['isbn'],
                    book['title'],
                    book['author'],
                    book['publisher_name'],
                    book['year'],
                    book['list_price'],
                    datetime.utcnow()
                ))
                added += 1
            except Exception as e:
                print(f"      [ì‚½ì… ì—ëŸ¬] ISBN {isbn}: {str(e)[:50]}")

    if not dry_run:
        conn.commit()

    return added, duplicates


def expand_books_with_textbooks(
    dry_run: bool = False,
    db_path: str = 'coupang_auto_backup.db',
    series_limit: int = None
):
    """
    Books í…Œì´ë¸”ì„ ì£¼ìš” êµì¬ë¡œ í™•ì¥

    Args:
        dry_run: ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ
        db_path: DB ê²½ë¡œ
        series_limit: ì²˜ë¦¬í•  ì‹œë¦¬ì¦ˆ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
    """
    # ì•Œë¼ë”˜ API ì´ˆê¸°í™”
    TTB_KEY = os.getenv('ALADIN_TTB_KEY')
    if not TTB_KEY:
        print('âŒ ALADIN_TTB_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
        sys.exit(1)

    crawler = AladinAPICrawler(TTB_KEY)

    # DB ì—°ê²°
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    print("=" * 80)
    print("Books í…Œì´ë¸” í™•ì¥ - ì£¼ìš” êµì¬ ì‹œë¦¬ì¦ˆ í¬ë¡¤ë§")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN (ë¯¸ë¦¬ë³´ê¸°)' if dry_run else 'LIVE (ì‹¤ì œ ì¶”ê°€)'}")
    if series_limit:
        print(f"ì œí•œ: ìµœëŒ€ {series_limit}ê°œ ì‹œë¦¬ì¦ˆ")
    print()

    # í˜„ì¬ Books í…Œì´ë¸” ìƒíƒœ
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM books")
    initial_count = cursor.fetchone()[0]
    print(f"ğŸ“š í˜„ì¬ Books í…Œì´ë¸”: {initial_count:,}ê°œ")
    print()

    # í†µê³„
    stats = {
        'series_processed': 0,
        'total_found': 0,
        'total_added': 0,
        'total_duplicates': 0,
        'by_series': {}
    }

    # ì‹œë¦¬ì¦ˆë³„ í¬ë¡¤ë§
    series_to_process = MAJOR_TEXTBOOK_SERIES[:series_limit] if series_limit else MAJOR_TEXTBOOK_SERIES

    for idx, (series_name, subjects) in enumerate(series_to_process, 1):
        print(f"[{idx}/{len(series_to_process)}] ì‹œë¦¬ì¦ˆ: {series_name}")

        # ê²€ìƒ‰
        aladin_results = search_textbook_series(crawler, series_name, subjects)

        # ì¤‘ë³µ ì œê±° (ISBN ê¸°ì¤€)
        unique_books = {}
        for item in aladin_results:
            book_info = extract_book_info(item)
            isbn = book_info['isbn']
            if isbn and isbn not in unique_books:
                unique_books[isbn] = book_info

        books = list(unique_books.values())

        print(f"  ì¤‘ë³µ ì œê±° í›„: {len(books)}ê°œ")

        # DB ì‚½ì…
        added, duplicates = insert_books_to_db(books, conn, dry_run)

        print(f"  ê²°ê³¼: ì¶”ê°€ {added}ê°œ, ì¤‘ë³µ {duplicates}ê°œ")
        print()

        stats['series_processed'] += 1
        stats['total_found'] += len(aladin_results)
        stats['total_added'] += added
        stats['total_duplicates'] += duplicates
        stats['by_series'][series_name] = {
            'found': len(aladin_results),
            'unique': len(books),
            'added': added,
            'duplicates': duplicates
        }

        # API ì œí•œ ì¤€ìˆ˜
        time.sleep(1.0)

    # ìµœì¢… ìƒíƒœ
    cursor.execute("SELECT COUNT(*) FROM books")
    final_count = cursor.fetchone()[0]

    print("=" * 80)
    print("í¬ë¡¤ë§ ê²°ê³¼")
    print("=" * 80)
    print(f"ì²˜ë¦¬í•œ ì‹œë¦¬ì¦ˆ: {stats['series_processed']}ê°œ")
    print(f"ë°œê²¬í•œ ë„ì„œ: {stats['total_found']:,}ê°œ")
    print(f"ì¤‘ë³µ ì œê±° í›„: {stats['total_found'] - stats['total_duplicates']:,}ê°œ")
    print(f"ì¶”ê°€ëœ ë„ì„œ: {stats['total_added']:,}ê°œ")
    print(f"ì¤‘ë³µ ìŠ¤í‚µ: {stats['total_duplicates']:,}ê°œ")
    print()

    print("ğŸ“š Books í…Œì´ë¸”:")
    print(f"  ì´ì „: {initial_count:,}ê°œ")
    print(f"  í˜„ì¬: {final_count:,}ê°œ")
    print(f"  ì¦ê°€: +{final_count - initial_count:,}ê°œ")
    print()

    # ì‹œë¦¬ì¦ˆë³„ ìƒì„¸
    print("ğŸ“Š ì‹œë¦¬ì¦ˆë³„ ìƒì„¸:")
    print("-" * 80)
    for series, data in sorted(stats['by_series'].items(), key=lambda x: -x[1]['added'])[:10]:
        print(f"{series:15s}: ë°œê²¬ {data['found']:3d}ê°œ â†’ ì¶”ê°€ {data['added']:3d}ê°œ (ì¤‘ë³µ {data['duplicates']:3d})")

    print()
    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    conn.close()

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Books í…Œì´ë¸” í™•ì¥')
    parser.add_argument('--dry-run', action='store_true', help='ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ')
    parser.add_argument('--db', type=str, default='coupang_auto_backup.db', help='DB ê²½ë¡œ')
    parser.add_argument('--limit', type=int, help='ì‹œë¦¬ì¦ˆ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)')

    args = parser.parse_args()

    try:
        stats = expand_books_with_textbooks(
            dry_run=args.dry_run,
            db_path=args.db,
            series_limit=args.limit
        )

        print()
        print("âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
        if not args.dry_run:
            print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: python scripts/fill_isbn_smart_matching.py")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
