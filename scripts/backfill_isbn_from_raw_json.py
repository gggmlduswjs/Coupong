"""
Phase 1: raw_jsonì—ì„œ ISBN ì¬íŒŒì‹± ìŠ¤í¬ë¦½íŠ¸

raw_json ë°ì´í„°ì—ì„œ ISBNì„ ê°•í™”ëœ ë°©ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ listings í…Œì´ë¸”ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
- ëª¨ë“  items í™•ì¸ (ì²« ë²ˆì§¸ë§Œ X)
- attributes, externalVendorSku, barcode, searchTags ëª¨ë‘ ê²€ì‚¬
- ISBN-13 ì²´í¬ì„¬ ê²€ì¦
- API í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ì‹¤í–‰ (ì˜ˆìƒ: 5-10ë¶„)

ì˜ˆìƒ ì„±ê³¼: +800~1,200 ISBN
"""
import re
import json
import sys
import io
from pathlib import Path
from datetime import datetime
from typing import List, Optional, Tuple

# UTF-8 ì¶œë ¥ ì„¤ì • (Windows ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sqlalchemy import text
from app.database import get_db
from app.models.listing import Listing


def validate_isbn13_checksum(isbn: str) -> bool:
    """
    ISBN-13 ì²´í¬ì„¬ ê²€ì¦

    ISBN-13ì€ 978/979ë¡œ ì‹œì‘í•˜ëŠ” 13ìë¦¬ ìˆ«ìì´ë©°,
    ë§ˆì§€ë§‰ ìë¦¬ëŠ” ì²´í¬ ë””ì§€íŠ¸ì…ë‹ˆë‹¤.

    ê²€ì¦ ì•Œê³ ë¦¬ì¦˜:
    1. ì²« 12ìë¦¬ì˜ ê°€ì¤‘ì¹˜ í•© ê³„ì‚° (í™€ìˆ˜ ìë¦¬ëŠ” 1, ì§ìˆ˜ ìë¦¬ëŠ” 3)
    2. (10 - (í•©ê³„ % 10)) % 10 = ì²´í¬ ë””ì§€íŠ¸
    """
    if not isbn or len(isbn) != 13:
        return False

    if not isbn.isdigit():
        return False

    if not isbn.startswith(('978', '979')):
        return False

    try:
        check_sum = sum(
            int(isbn[i]) * (1 if i % 2 == 0 else 3)
            for i in range(12)
        )
        calculated_check = (10 - (check_sum % 10)) % 10
        return calculated_check == int(isbn[12])
    except (ValueError, IndexError):
        return False


def extract_all_isbns_from_raw_json(raw_json_str: str) -> List[str]:
    """
    raw_jsonì—ì„œ ëª¨ë“  ISBN ì¶”ì¶œ (ê°•í™” ë²„ì „)

    ê¸°ì¡´ _extract_isbn() í•¨ìˆ˜ì˜ í•œê³„:
    - ì²« ë²ˆì§¸ itemë§Œ í™•ì¸
    - attributesì˜ "í•´ë‹¹ì—†ìŒ" ë’¤ì— ìˆëŠ” ISBN ë†“ì¹¨
    - externalVendorSku ë¯¸ê²€ì‚¬

    ê°œì„ ì‚¬í•­:
    - ëª¨ë“  items ìˆœíšŒ
    - ëª¨ë“  í•„ë“œ ì² ì €íˆ ê²€ì‚¬
    - ISBN-13 ì²´í¬ì„¬ ê²€ì¦
    - ì¤‘ë³µ ì œê±°

    Returns:
        ê²€ì¦ëœ ISBN ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°ë¨)
    """
    if not raw_json_str:
        return []

    try:
        data = json.loads(raw_json_str)
    except json.JSONDecodeError:
        return []

    isbn_pattern = re.compile(r'97[89]\d{10}')
    found_isbns = set()

    items = data.get('items', [])
    if not items:
        return []

    for item in items:
        # 1. attributes ë°°ì—´ì—ì„œ ì¶”ì¶œ (ê°€ì¥ ì •í™•)
        attributes = item.get('attributes', [])
        if isinstance(attributes, list):
            for attr in attributes:
                attr_name = attr.get('attributeTypeName', '')
                attr_value = attr.get('attributeValueName', '')

                if attr_name == 'ISBN' and attr_value:
                    # "ìƒì„¸í˜ì´ì§€ ì°¸ì¡°", "í•´ë‹¹ì—†ìŒ" ë“± ì œì™¸
                    if any(skip in attr_value for skip in ['ìƒì„¸', 'ì°¸ì¡°', 'í•´ë‹¹ì—†ìŒ', 'ì—†ìŒ']):
                        continue

                    # ìˆ«ìë§Œ ì¶”ì¶œ
                    cleaned = re.sub(r'[^0-9]', '', attr_value)
                    if validate_isbn13_checksum(cleaned):
                        found_isbns.add(cleaned)

                # ë‹¤ë¥¸ ì†ì„± ê°’ì—ì„œë„ ISBN íŒ¨í„´ ê²€ìƒ‰
                matches = isbn_pattern.findall(str(attr_value))
                for isbn in matches:
                    if validate_isbn13_checksum(isbn):
                        found_isbns.add(isbn)

        # 2. barcode í•„ë“œ
        barcode = str(item.get('barcode', ''))
        matches = isbn_pattern.findall(barcode)
        for isbn in matches:
            if validate_isbn13_checksum(isbn):
                found_isbns.add(isbn)

        # 3. externalVendorSku (ê¸°ì¡´ì— ëˆ„ë½ë¨!)
        external_sku = str(item.get('externalVendorSku', ''))
        matches = isbn_pattern.findall(external_sku)
        for isbn in matches:
            if validate_isbn13_checksum(isbn):
                found_isbns.add(isbn)

        # 4. searchTags ë°°ì—´
        search_tags = item.get('searchTags', [])
        if isinstance(search_tags, list):
            for tag in search_tags:
                matches = isbn_pattern.findall(str(tag))
                for isbn in matches:
                    if validate_isbn13_checksum(isbn):
                        found_isbns.add(isbn)

        # 5. vendorItemName
        vendor_name = str(item.get('vendorItemName', ''))
        matches = isbn_pattern.findall(vendor_name)
        for isbn in matches:
            if validate_isbn13_checksum(isbn):
                found_isbns.add(isbn)

    # 6. ìµœìƒìœ„ ë ˆë²¨ í•„ë“œë“¤ë„ ê²€ì‚¬
    product_name = str(data.get('sellerProductName', ''))
    matches = isbn_pattern.findall(product_name)
    for isbn in matches:
        if validate_isbn13_checksum(isbn):
            found_isbns.add(isbn)

    return sorted(list(found_isbns))


def backfill_isbn_from_raw_json(dry_run: bool = False, limit: int = None, db_path: str = None):
    """
    raw_jsonì—ì„œ ISBNì„ ì¶”ì¶œí•˜ì—¬ listings í…Œì´ë¸” ì—…ë°ì´íŠ¸

    Args:
        dry_run: Trueì¼ ê²½ìš° ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ
        limit: ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
        db_path: ì‚¬ìš©í•  DB íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ì„¤ì •)
    """
    if db_path:
        # ì§ì ‘ SQLite ì—°ê²°
        import sqlite3
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        db = conn
        use_raw_sqlite = True
    else:
        db = next(get_db())
        use_raw_sqlite = False

    print("=" * 80)
    print("Phase 1: raw_jsonì—ì„œ ISBN ì¬íŒŒì‹±")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN (ë¯¸ë¦¬ë³´ê¸°)' if dry_run else 'LIVE (ì‹¤ì œ ì—…ë°ì´íŠ¸)'}")
    if limit:
        print(f"ì œí•œ: ìµœëŒ€ {limit}ê°œ ë ˆì½”ë“œ")
    print()

    # ISBNì´ ì—†ê³  raw_jsonì´ ìˆëŠ” listings ì¡°íšŒ
    query = """
        SELECT id, raw_json, product_name
        FROM listings
        WHERE isbn IS NULL
          AND raw_json IS NOT NULL
          AND raw_json != ''
    """

    if limit:
        query += f" LIMIT {limit}"

    if use_raw_sqlite:
        cursor = db.cursor()
        cursor.execute(query)
        candidates = cursor.fetchall()
    else:
        result = db.execute(text(query))
        candidates = result.fetchall()

    print(f"ğŸ“Š ëŒ€ìƒ ë ˆì½”ë“œ: {len(candidates):,}ê°œ")
    print()

    # í†µê³„
    stats = {
        'total': len(candidates),
        'success': 0,
        'failed': 0,
        'single_isbn': 0,
        'multiple_isbn': 0,
        'invalid_isbn': 0
    }

    updated_listings = []

    for idx, row in enumerate(candidates, 1):
        listing_id = row[0]
        raw_json = row[1]
        product_name = row[2]

        # ISBN ì¶”ì¶œ
        isbns = extract_all_isbns_from_raw_json(raw_json)

        if isbns:
            isbn_str = ','.join(isbns)

            # í†µê³„ ì—…ë°ì´íŠ¸
            stats['success'] += 1
            if len(isbns) == 1:
                stats['single_isbn'] += 1
            else:
                stats['multiple_isbn'] += 1

            updated_listings.append((listing_id, isbn_str, product_name))

            # ì§„í–‰ ìƒí™© ì¶œë ¥ (100ê°œë§ˆë‹¤)
            if idx % 100 == 0:
                print(f"âœ“ ì§„í–‰: {idx:,}/{len(candidates):,} ({idx/len(candidates)*100:.1f}%) - ì„±ê³µ: {stats['success']:,}")
        else:
            stats['failed'] += 1

    print()
    print("=" * 80)
    print("ì¶”ì¶œ ê²°ê³¼")
    print("=" * 80)
    print(f"ì´ ì²˜ë¦¬: {stats['total']:,}ê°œ")
    print(f"âœ… ì„±ê³µ: {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
    print(f"   - ë‹¨ì¼ ISBN: {stats['single_isbn']:,}ê°œ")
    print(f"   - ë³µìˆ˜ ISBN: {stats['multiple_isbn']:,}ê°œ (ì„¸íŠ¸ ìƒí’ˆ)")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed']:,}ê°œ ({stats['failed']/stats['total']*100:.1f}%)")
    print()

    # ìƒ˜í”Œ ì¶œë ¥ (ì²˜ìŒ 10ê°œ)
    if updated_listings:
        print("ğŸ“ ì¶”ì¶œ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
        print("-" * 80)
        for listing_id, isbn, product_name in updated_listings[:10]:
            isbn_count = len(isbn.split(','))
            isbn_type = "ì„¸íŠ¸" if isbn_count > 1 else "ë‹¨ê¶Œ"
            print(f"ID {listing_id:5d} | ISBN: {isbn[:30]:30s} | [{isbn_type}] {product_name[:40]}")
        print()

    if not dry_run:
        # ì‹¤ì œ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")

        update_count = 0
        duplicate_count = 0

        for listing_id, isbn_str, _ in updated_listings:
            try:
                if use_raw_sqlite:
                    cursor = db.cursor()

                    # ì¤‘ë³µ ì²´í¬: ê°™ì€ account_idì— ê°™ì€ ISBNì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                    cursor.execute("""
                        SELECT account_id FROM listings WHERE id = ?
                    """, (listing_id,))
                    row = cursor.fetchone()
                    if not row:
                        continue

                    account_id = row[0]

                    # ê°™ì€ ê³„ì •ì— ê°™ì€ ISBNì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                    cursor.execute("""
                        SELECT COUNT(*) FROM listings
                        WHERE account_id = ? AND isbn = ? AND id != ?
                    """, (account_id, isbn_str, listing_id))

                    if cursor.fetchone()[0] > 0:
                        # ì¤‘ë³µì´ë¯€ë¡œ ìŠ¤í‚µ
                        duplicate_count += 1
                        continue

                    # ì—…ë°ì´íŠ¸ ìˆ˜í–‰
                    cursor.execute("UPDATE listings SET isbn = ? WHERE id = ?", (isbn_str, listing_id))
                else:
                    db.execute(
                        text("UPDATE listings SET isbn = :isbn WHERE id = :id"),
                        {"isbn": isbn_str, "id": listing_id}
                    )
                update_count += 1

                # 100ê°œë§ˆë‹¤ ì»¤ë°‹ (ì²´í¬í¬ì¸íŠ¸)
                if update_count % 100 == 0:
                    db.commit()
                    print(f"   ì²´í¬í¬ì¸íŠ¸: {update_count:,}ê°œ ì»¤ë°‹ë¨ (ì¤‘ë³µ ìŠ¤í‚µ: {duplicate_count:,})")
            except Exception as e:
                if "UNIQUE constraint" not in str(e):
                    print(f"âš ï¸  ID {listing_id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                else:
                    duplicate_count += 1
                continue

        # ìµœì¢… ì»¤ë°‹
        db.commit()
        print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_count:,}ê°œ")
        if duplicate_count > 0:
            print(f"âš ï¸  ì¤‘ë³µìœ¼ë¡œ ìŠ¤í‚µ: {duplicate_count:,}ê°œ (ê°™ì€ ê³„ì •ì— ê°™ì€ ISBN ì´ë¯¸ ì¡´ì¬)")
    else:
        print("âš ï¸  DRY RUN ëª¨ë“œ - ë³€ê²½ì‚¬í•­ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    print()
    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='raw_jsonì—ì„œ ISBN ì¬íŒŒì‹±')
    parser.add_argument('--dry-run', action='store_true', help='ë³€ê²½ì‚¬í•­ì„ ì €ì¥í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')
    parser.add_argument('--limit', type=int, help='ì²˜ë¦¬í•  ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')
    parser.add_argument('--db', type=str, help='ì‚¬ìš©í•  DB íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: coupang_auto_backup.db)')

    args = parser.parse_args()

    # ê¸°ë³¸ê°’ìœ¼ë¡œ backup DB ì‚¬ìš©
    db_path = args.db or 'coupang_auto_backup.db'

    try:
        stats = backfill_isbn_from_raw_json(dry_run=args.dry_run, limit=args.limit, db_path=db_path)

        print()
        print("ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"   ì„±ê³µë¥ : {stats['success']/stats['total']*100:.1f}%")
        print(f"   ë‹¨ì¼ ISBN: {stats['single_isbn']:,}ê°œ")
        print(f"   ë³µìˆ˜ ISBN: {stats['multiple_isbn']:,}ê°œ")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
