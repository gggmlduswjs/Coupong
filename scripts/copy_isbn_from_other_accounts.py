"""
ë‹¤ë¥¸ ê³„ì •ì—ì„œ ISBN ë³µì‚¬

ê°™ì€ ìƒí’ˆì„ íŒë§¤í•˜ëŠ” ë‹¤ë¥¸ ê³„ì •ì˜ ISBNì„ ë³µì‚¬í•©ë‹ˆë‹¤.
- ìƒí’ˆëª… ê¸°ë°˜ ë§¤ì¹­ (ì •ê·œí™” í›„ ë¹„êµ)
- ê³„ì •ê°„ ISBN ê³µìœ  (UNIQUE constraint í—ˆìš©)
- ë†’ì€ ì‹ ë¢°ë„ ë§¤ì¹­ë§Œ ìˆ˜í–‰
"""
import sys
import io
import re
import sqlite3
from datetime import datetime
from typing import Optional, List, Tuple

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def normalize_product_name(name: str) -> str:
    """
    ìƒí’ˆëª… ì •ê·œí™” (ë§¤ì¹­ìš©)

    - ì†Œë¬¸ì ë³€í™˜
    - ê´„í˜¸/ì‚¬ì€í’ˆ/ì„ ë¬¼ ë“± ì œê±°
    - ê³µë°± ì •ë¦¬
    """
    if not name:
        return ""

    # ì†Œë¬¸ì
    normalized = name.lower()

    # ì œê±°í•  íŒ¨í„´
    patterns_to_remove = [
        r'\(.*?\)',  # ê´„í˜¸
        r'\[.*?\]',  # ëŒ€ê´„í˜¸
        r'ì‚¬ì€í’ˆ',
        r'ì„ ë¬¼',
        r'ì¦ì •',
        r'ë¬´ë£Œë°°ì†¡',
        r'\+',  # + ê¸°í˜¸
        r'&',   # & ê¸°í˜¸
        r'ì„¸íŠ¸',
    ]

    for pattern in patterns_to_remove:
        normalized = re.sub(pattern, ' ', normalized)

    # ì—°ì† ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
    normalized = re.sub(r'\s+', ' ', normalized)

    return normalized.strip()


def calculate_similarity(name1: str, name2: str) -> float:
    """
    ë‘ ìƒí’ˆëª…ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)

    ê°„ë‹¨í•œ ë‹¨ì–´ ì§‘í•© ê¸°ë°˜ Jaccard ìœ ì‚¬ë„
    """
    if not name1 or not name2:
        return 0.0

    # ì •ê·œí™”
    norm1 = normalize_product_name(name1)
    norm2 = normalize_product_name(name2)

    # ë‹¨ì–´ ì§‘í•©
    words1 = set(norm1.split())
    words2 = set(norm2.split())

    if not words1 or not words2:
        return 0.0

    # Jaccard ìœ ì‚¬ë„
    intersection = len(words1 & words2)
    union = len(words1 | words2)

    return intersection / union if union > 0 else 0.0


def find_isbn_from_other_accounts(
    product_name: str,
    account_id: int,
    conn,
    min_similarity: float = 0.7
) -> Optional[str]:
    """
    ë‹¤ë¥¸ ê³„ì •ì—ì„œ ìœ ì‚¬í•œ ìƒí’ˆì˜ ISBN ì°¾ê¸°

    Args:
        product_name: ê²€ìƒ‰í•  ìƒí’ˆëª…
        account_id: í˜„ì¬ ê³„ì • ID
        conn: DB ì—°ê²°
        min_similarity: ìµœì†Œ ìœ ì‚¬ë„ (0.7 = 70%)

    Returns:
        ISBN ë˜ëŠ” None
    """
    cursor = conn.cursor()

    # ë‹¤ë¥¸ ê³„ì •ì˜ ISBNì´ ìˆëŠ” ìƒí’ˆë“¤ ì¡°íšŒ
    cursor.execute("""
        SELECT product_name, isbn
        FROM listings
        WHERE account_id != ?
          AND isbn IS NOT NULL
          AND isbn != ''
          AND product_name IS NOT NULL
    """, (account_id,))

    candidates = cursor.fetchall()

    # ìœ ì‚¬ë„ ê³„ì‚°
    best_match = None
    best_similarity = 0.0

    for candidate_name, candidate_isbn in candidates:
        similarity = calculate_similarity(product_name, candidate_name)

        if similarity > best_similarity and similarity >= min_similarity:
            best_similarity = similarity
            best_match = (candidate_isbn, candidate_name, similarity)

    if best_match:
        return best_match[0]  # ISBN ë°˜í™˜

    return None


def copy_isbn_from_other_accounts(
    dry_run: bool = False,
    limit: int = None,
    db_path: str = 'coupang_auto_backup.db',
    account_id: int = None,
    min_similarity: float = 0.8
):
    """
    ë‹¤ë¥¸ ê³„ì •ì—ì„œ ISBN ë³µì‚¬

    Args:
        min_similarity: ìµœì†Œ ìœ ì‚¬ë„ (ê¸°ë³¸ê°’ 0.8 = 80%)
    """
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    print("=" * 80)
    print("ë‹¤ë¥¸ ê³„ì •ì—ì„œ ISBN ë³µì‚¬")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN' if dry_run else 'LIVE'}")
    print(f"ìµœì†Œ ìœ ì‚¬ë„: {min_similarity * 100:.0f}%")
    if limit:
        print(f"ì œí•œ: {limit}ê°œ")
    if account_id:
        print(f"ê³„ì •: ID {account_id}")
    print()

    # ISBN ì—†ëŠ” ìƒí’ˆ ì¡°íšŒ
    query = """
        SELECT id, account_id, product_name
        FROM listings
        WHERE (isbn IS NULL OR isbn = '')
        AND product_name IS NOT NULL
        AND product_name != ''
    """

    params = []
    if account_id:
        query += " AND account_id = ?"
        params.append(account_id)

    query += " ORDER BY id"

    if limit:
        query += f" LIMIT {limit}"

    cursor = conn.cursor()
    cursor.execute(query, params)
    candidates = cursor.fetchall()

    print(f"ğŸ” ëŒ€ìƒ: {len(candidates):,}ê°œ")
    print()

    stats = {
        'total': len(candidates),
        'success': 0,
        'failed': 0,
        'duplicate': 0,
        'by_similarity': {
            '80-85%': 0,
            '85-90%': 0,
            '90-95%': 0,
            '95-100%': 0
        }
    }

    updated_listings = []

    for idx, row in enumerate(candidates, 1):
        listing_id = row[0]
        acc_id = row[1]
        product_name = row[2]

        # ë‹¤ë¥¸ ê³„ì •ì—ì„œ ISBN ì°¾ê¸°
        isbn = find_isbn_from_other_accounts(product_name, acc_id, conn, min_similarity)

        if isbn:
            # ìœ ì‚¬ë„ ì¬ê³„ì‚° (ì¶œë ¥ìš©)
            cursor.execute("""
                SELECT product_name FROM listings
                WHERE isbn = ? AND account_id != ? LIMIT 1
            """, (isbn, acc_id))

            source_row = cursor.fetchone()
            if source_row:
                similarity = calculate_similarity(product_name, source_row[0])

                # ìœ ì‚¬ë„ ë²”ìœ„ë³„ í†µê³„
                if similarity >= 0.95:
                    stats['by_similarity']['95-100%'] += 1
                elif similarity >= 0.90:
                    stats['by_similarity']['90-95%'] += 1
                elif similarity >= 0.85:
                    stats['by_similarity']['85-90%'] += 1
                else:
                    stats['by_similarity']['80-85%'] += 1

                stats['success'] += 1
                updated_listings.append((listing_id, isbn, product_name, source_row[0], similarity))

                if stats['success'] <= 10:
                    print(f"âœ“ [{stats['success']}] {product_name[:55]}")
                    print(f"   â†’ ISBN: {isbn} | ìœ ì‚¬ë„: {similarity*100:.1f}%")
                    print(f"   â† ì›ë³¸: {source_row[0][:55]}")
        else:
            stats['failed'] += 1

        if idx % 100 == 0:
            print(f"ì§„í–‰: {idx:,}/{len(candidates):,} ({idx/len(candidates)*100:.1f}%) - ì„±ê³µ: {stats['success']:,}")

    print()
    print("=" * 80)
    print("ì²˜ë¦¬ ê²°ê³¼")
    print("=" * 80)
    print(f"ì´ ì²˜ë¦¬: {stats['total']:,}ê°œ")
    print(f"âœ… ì„±ê³µ: {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed']:,}ê°œ")
    print()

    if stats['success'] > 0:
        print("ğŸ“Š ìœ ì‚¬ë„ ë¶„í¬:")
        for range_name, count in sorted(stats['by_similarity'].items(), reverse=True):
            if count > 0:
                print(f"   {range_name}: {count:4d}ê°œ ({count/stats['success']*100:.1f}%)")
        print()

    if not dry_run and updated_listings:
        print("ğŸ’¾ ì—…ë°ì´íŠ¸ ì¤‘...")

        update_count = 0
        duplicate_count = 0

        for listing_id, isbn, product_name, source_name, similarity in updated_listings:
            try:
                cursor = conn.cursor()

                cursor.execute("SELECT account_id FROM listings WHERE id = ?", (listing_id,))
                row = cursor.fetchone()
                if not row:
                    continue

                acc_id = row[0]

                # ì¤‘ë³µ ì²´í¬
                cursor.execute("""
                    SELECT COUNT(*) FROM listings
                    WHERE account_id = ? AND isbn = ? AND id != ?
                """, (acc_id, isbn, listing_id))

                if cursor.fetchone()[0] > 0:
                    duplicate_count += 1
                    continue

                cursor.execute("UPDATE listings SET isbn = ? WHERE id = ?", (isbn, listing_id))
                update_count += 1

                if update_count % 100 == 0:
                    conn.commit()
                    print(f"   ì²´í¬í¬ì¸íŠ¸: {update_count:,}ê°œ")

            except Exception as e:
                continue

        conn.commit()
        print(f"âœ… ì™„ë£Œ: {update_count:,}ê°œ")
        if duplicate_count > 0:
            print(f"âš ï¸  ì¤‘ë³µ: {duplicate_count:,}ê°œ")
    else:
        print("âš ï¸  DRY RUN")

    conn.close()

    print()
    print(f"ì¢…ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ë‹¤ë¥¸ ê³„ì •ì—ì„œ ISBN ë³µì‚¬')
    parser.add_argument('--dry-run', action='store_true')
    parser.add_argument('--limit', type=int)
    parser.add_argument('--db', type=str, default='coupang_auto_backup.db')
    parser.add_argument('--account', type=int)
    parser.add_argument('--similarity', type=float, default=0.8, help='ìµœì†Œ ìœ ì‚¬ë„ (0.0~1.0)')

    args = parser.parse_args()

    try:
        stats = copy_isbn_from_other_accounts(
            dry_run=args.dry_run,
            limit=args.limit,
            db_path=args.db,
            account_id=args.account,
            min_similarity=args.similarity
        )

        print()
        print(f"ğŸ“Š ì„±ê³µë¥ : {stats['success']/stats['total']*100:.1f}%")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
