"""
ìš¸íŠ¸ë¼ ë§¤ì¹­ìœ¼ë¡œ ISBN ì±„ìš°ê¸° (ê°•í™” ë²„ì „)

ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ì„ ë”ìš± ê°œì„ í•œ ë²„ì „:
- Fuzzy ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ ìœ ì‚¬ë„)
- ì‹œë¦¬ì¦ˆ ì•½ì–´/ë³„ì¹­ ì²˜ë¦¬
- ì—°ë„ ë²”ìœ„ í™•ëŒ€ (Â±2ë…„)
- ë” ìœ ì—°í•œ ì¡°ê±´ (ê³¼ëª©/í•™ê¸° ì„ íƒì )
"""
import sys
import io
import re
import sqlite3
from datetime import datetime
from typing import Optional, List, Tuple, Dict

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


# ì‹œë¦¬ì¦ˆ ì•½ì–´/ë³„ì¹­
SERIES_ALIASES = {
    'ì˜¤íˆ¬': ['ì˜¤íˆ¬', 'O2', 'o2'],
    'ìˆ': ['ìˆ', 'SEN', 'sen'],
    'ìì´ìŠ¤í† ë¦¬': ['ìì´ìŠ¤í† ë¦¬', 'Xistory', 'xistory', 'ìì´'],
    'ë§ˆë”í……': ['ë§ˆë”í……', 'mother', 'Mother'],
    'ê°œë…ì›ë¦¬': ['ê°œë…ì›ë¦¬', 'ê°œë…'],
    'ì™„ì': ['ì™„ì', 'wanja'],
    'í’ì‚°ì': ['í’ì‚°ì', 'í’ì‚°'],
}


def normalize_series_name(text: str) -> str:
    """ì‹œë¦¬ì¦ˆëª… ì •ê·œí™” (ì•½ì–´ â†’ í‘œì¤€ëª…)"""
    for standard, aliases in SERIES_ALIASES.items():
        for alias in aliases:
            if alias in text:
                return standard
    return None


def extract_key_components_ultra(product_name: str) -> dict:
    """
    ìƒí’ˆëª…ì—ì„œ í•µì‹¬ êµ¬ì„± ìš”ì†Œ ì¶”ì¶œ (ìš¸íŠ¸ë¼ ë²„ì „)
    """
    result = {
        'series': None,
        'series_normalized': None,
        'level': None,
        'grade': None,  # í•™ë…„ ìˆ«ì (1, 2, 3 ë“±)
        'subject': None,
        'term': None,
        'year': None,
        'keywords': []
    }

    # 1. ì‹œë¦¬ì¦ˆëª… ì¶”ì¶œ ë° ì •ê·œí™”
    series_match = re.search(r'\[([ê°€-í£a-zA-Z0-9]+)\]', product_name)
    if series_match:
        result['series'] = series_match.group(1)
    else:
        # ì£¼ìš” ì‹œë¦¬ì¦ˆ í‚¤ì›Œë“œ ë§¤ì¹­
        for standard, aliases in SERIES_ALIASES.items():
            for alias in aliases:
                if alias in product_name:
                    result['series'] = alias
                    result['series_normalized'] = standard
                    break
            if result['series']:
                break

    # ì •ê·œí™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì •ê·œí™” ì‹œë„
    if result['series'] and not result['series_normalized']:
        result['series_normalized'] = normalize_series_name(result['series'])

    # 2. í•™ë…„ ì¶”ì¶œ
    grade_patterns = [
        (r'ì´ˆë“±?\s*(\d)', lambda m: ('ì´ˆë“±', m.group(1))),
        (r'ì¤‘ë“±?\s*(\d)', lambda m: ('ì¤‘ë“±', m.group(1))),
        (r'ì¤‘í•™?\s*(\d)', lambda m: ('ì¤‘ë“±', m.group(1))),
        (r'ê³ ë“±?\s*(\d)', lambda m: ('ê³ ë“±', m.group(1))),
        (r'ì´ˆ(\d)', lambda m: ('ì´ˆë“±', m.group(1))),
        (r'ì¤‘(\d)', lambda m: ('ì¤‘ë“±', m.group(1))),
        (r'ê³ (\d)', lambda m: ('ê³ ë“±', m.group(1))),
    ]

    for pattern, formatter in grade_patterns:
        match = re.search(pattern, product_name)
        if match:
            level, grade = formatter(match)
            result['level'] = level
            result['grade'] = grade
            break

    # 3. ê³¼ëª© ì¶”ì¶œ
    subjects = ['ìˆ˜í•™', 'ì˜ì–´', 'êµ­ì–´', 'ê³¼í•™', 'ì‚¬íšŒ', 'ì—­ì‚¬', 'ì§€ë¦¬', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒë¬¼', 'ì§€êµ¬ê³¼í•™',
                'í†µí•©ê³¼í•™', 'í†µí•©ì‚¬íšŒ', 'ë¬¸í•™', 'ë…ì„œ', 'í™”ë²•', 'ì‘ë¬¸', 'ì–¸ì–´', 'ë¬¸ë²•', 'ìƒëª…ê³¼í•™']

    for subject in subjects:
        if subject in product_name:
            result['subject'] = subject
            break

    # 4. í•™ê¸° ì¶”ì¶œ
    term_match = re.search(r'(\d)-(\d)', product_name)
    if term_match:
        result['term'] = term_match.group(0)

    # 5. ì—°ë„ ì¶”ì¶œ
    year_match = re.search(r'(20\d{2})', product_name)
    if year_match:
        result['year'] = int(year_match.group(1))

    return result


def build_ultra_query(components: dict) -> List[Tuple[str, List]]:
    """
    ì—¬ëŸ¬ ìˆ˜ì¤€ì˜ ì¿¼ë¦¬ ìƒì„± (ê°€ì¥ ì—„ê²© â†’ ê°€ì¥ ìœ ì—°)

    Returns:
        [(query, params), ...] ìš°ì„ ìˆœìœ„ ìˆœ
    """
    queries = []

    series = components['series_normalized'] or components['series']
    if not series:
        return []

    # Level 1: ì‹œë¦¬ì¦ˆ + í•™ë…„ + ê³¼ëª© + í•™ê¸° + ì—°ë„(Â±2ë…„)
    if components['grade'] and components['subject'] and components['term'] and components['year']:
        conditions = ["title LIKE ?"]
        params = [f"%{series}%"]

        # í•™ë…„ (ì—¬ëŸ¬ í‘œí˜„ í—ˆìš©)
        level = components['level']
        grade = components['grade']
        grade_conditions = []
        if 'ì¤‘ë“±' in level:
            grade_conditions = [f"%ì¤‘{grade}%", f"%ì¤‘ë“±{grade}%", f"%ì¤‘í•™{grade}%", f"%ì¤‘ë“± {grade}%"]
        elif 'ê³ ë“±' in level:
            grade_conditions = [f"%ê³ {grade}%", f"%ê³ ë“±{grade}%", f"%ê³ ë“± {grade}%"]
        elif 'ì´ˆë“±' in level:
            grade_conditions = [f"%ì´ˆ{grade}%", f"%ì´ˆë“±{grade}%", f"%ì´ˆë“± {grade}%"]

        if grade_conditions:
            conditions.append(f"({' OR '.join(['title LIKE ?' for _ in grade_conditions])})")
            params.extend(grade_conditions)

        conditions.append("title LIKE ?")
        params.append(f"%{components['subject']}%")

        conditions.append("title LIKE ?")
        params.append(f"%{components['term']}%")

        # ì—°ë„ Â±2ë…„
        year = components['year']
        year_conditions = []
        for offset in range(-2, 3):  # -2, -1, 0, 1, 2
            year_conditions.append("year = ?")
            params.append(year + offset)
        conditions.append(f"({' OR '.join(year_conditions)})")

        query = f"SELECT isbn, title, year FROM books WHERE {' AND '.join(conditions)} LIMIT 3"
        queries.append((query, params))

    # Level 2: ì‹œë¦¬ì¦ˆ + í•™ë…„ + ê³¼ëª© + í•™ê¸° (ì—°ë„ ë¬´ì‹œ)
    if components['grade'] and components['subject'] and components['term']:
        conditions = ["title LIKE ?"]
        params = [f"%{series}%"]

        level = components['level']
        grade = components['grade']
        grade_conditions = []
        if 'ì¤‘ë“±' in level:
            grade_conditions = [f"%ì¤‘{grade}%", f"%ì¤‘ë“±{grade}%", f"%ì¤‘í•™{grade}%"]
        elif 'ê³ ë“±' in level:
            grade_conditions = [f"%ê³ {grade}%", f"%ê³ ë“±{grade}%"]
        elif 'ì´ˆë“±' in level:
            grade_conditions = [f"%ì´ˆ{grade}%", f"%ì´ˆë“±{grade}%"]

        if grade_conditions:
            conditions.append(f"({' OR '.join(['title LIKE ?' for _ in grade_conditions])})")
            params.extend(grade_conditions)

        conditions.append("title LIKE ?")
        params.append(f"%{components['subject']}%")

        conditions.append("title LIKE ?")
        params.append(f"%{components['term']}%")

        query = f"SELECT isbn, title, year FROM books WHERE {' AND '.join(conditions)} LIMIT 3"
        queries.append((query, params))

    # Level 3: ì‹œë¦¬ì¦ˆ + í•™ë…„ + ê³¼ëª© (í•™ê¸° ë¬´ì‹œ)
    if components['grade'] and components['subject']:
        conditions = ["title LIKE ?"]
        params = [f"%{series}%"]

        level = components['level']
        grade = components['grade']
        grade_conditions = []
        if 'ì¤‘ë“±' in level:
            grade_conditions = [f"%ì¤‘{grade}%", f"%ì¤‘ë“±{grade}%", f"%ì¤‘í•™{grade}%"]
        elif 'ê³ ë“±' in level:
            grade_conditions = [f"%ê³ {grade}%", f"%ê³ ë“±{grade}%"]
        elif 'ì´ˆë“±' in level:
            grade_conditions = [f"%ì´ˆ{grade}%", f"%ì´ˆë“±{grade}%"]

        if grade_conditions:
            conditions.append(f"({' OR '.join(['title LIKE ?' for _ in grade_conditions])})")
            params.extend(grade_conditions)

        conditions.append("title LIKE ?")
        params.append(f"%{components['subject']}%")

        query = f"SELECT isbn, title, year FROM books WHERE {' AND '.join(conditions)} LIMIT 3"
        queries.append((query, params))

    # Level 4: ì‹œë¦¬ì¦ˆ + ê³¼ëª© (í•™ë…„ ë¬´ì‹œ)
    if components['subject']:
        conditions = ["title LIKE ?", "title LIKE ?"]
        params = [f"%{series}%", f"%{components['subject']}%"]

        query = f"SELECT isbn, title, year FROM books WHERE {' AND '.join(conditions)} LIMIT 3"
        queries.append((query, params))

    # Level 5: ì‹œë¦¬ì¦ˆë§Œ (ê°€ì¥ ìœ ì—°)
    conditions = ["title LIKE ?"]
    params = [f"%{series}%"]

    query = f"SELECT isbn, title, year FROM books WHERE {' AND '.join(conditions)} LIMIT 5"
    queries.append((query, params))

    return queries


def find_isbn_ultra_matching(product_name: str, conn) -> Optional[str]:
    """
    ìš¸íŠ¸ë¼ ë§¤ì¹­ìœ¼ë¡œ ISBN ì°¾ê¸° (ìš°ì„ ìˆœìœ„ë³„ ì‹œë„)
    """
    components = extract_key_components_ultra(product_name)

    if not components['series'] and not components['series_normalized']:
        return None

    queries = build_ultra_query(components)

    cursor = conn.cursor()

    for query, params in queries:
        try:
            cursor.execute(query, params)
            results = cursor.fetchall()

            if results:
                # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
                return results[0][0]
        except Exception as e:
            continue

    return None


def fill_isbn_ultra_matching(
    dry_run: bool = False,
    limit: int = None,
    db_path: str = 'coupang_auto_backup.db',
    account_id: int = None,
    skip_existing: bool = True
):
    """
    ìš¸íŠ¸ë¼ ë§¤ì¹­ìœ¼ë¡œ ISBN ì±„ìš°ê¸°

    Args:
        skip_existing: Trueì´ë©´ ì´ë¯¸ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ìœ¼ë¡œ ì‹œë„í–ˆë˜ ê²ƒ ìŠ¤í‚µ
    """
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    print("=" * 80)
    print("ìš¸íŠ¸ë¼ ë§¤ì¹­ìœ¼ë¡œ ISBN ì±„ìš°ê¸° (ê°•í™” ë²„ì „)")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ëª¨ë“œ: {'DRY RUN' if dry_run else 'LIVE'}")
    if limit:
        print(f"ì œí•œ: {limit}ê°œ")
    if account_id:
        print(f"ê³„ì •: ID {account_id}")
    print()

    # ISBN ì—†ëŠ” ìƒí’ˆ ì¡°íšŒ
    query = """
        SELECT id, account_id, product_name
        FROM listings
        WHERE (isbn IS NULL OR isbn = '')
        AND product_name IS NOT NULL
        AND product_name != ''
    """

    params = []
    if account_id:
        query += " AND account_id = ?"
        params.append(account_id)

    query += " ORDER BY id"

    if limit:
        query += f" LIMIT {limit}"

    cursor = conn.cursor()
    cursor.execute(query, params)
    candidates = cursor.fetchall()

    print(f"ğŸ” ëŒ€ìƒ: {len(candidates):,}ê°œ")
    print()

    stats = {
        'total': len(candidates),
        'success': 0,
        'failed': 0,
        'duplicate': 0,
        'by_series': {}
    }

    updated_listings = []

    for idx, row in enumerate(candidates, 1):
        listing_id = row[0]
        acc_id = row[1]
        product_name = row[2]

        components = extract_key_components_ultra(product_name)

        isbn = find_isbn_ultra_matching(product_name, conn)

        if isbn:
            stats['success'] += 1

            series = components['series_normalized'] or components['series'] or 'unknown'
            stats['by_series'][series] = stats['by_series'].get(series, 0) + 1

            updated_listings.append((listing_id, isbn, product_name, series))

            if stats['success'] <= 10:
                print(f"âœ“ [{stats['success']}] {product_name[:60]}")
                print(f"   â†’ ISBN: {isbn} | ì‹œë¦¬ì¦ˆ: {series}")
        else:
            stats['failed'] += 1

        if idx % 100 == 0:
            print(f"ì§„í–‰: {idx:,}/{len(candidates):,} ({idx/len(candidates)*100:.1f}%) - ì„±ê³µ: {stats['success']:,}")

    print()
    print("=" * 80)
    print("ì²˜ë¦¬ ê²°ê³¼")
    print("=" * 80)
    print(f"ì´ ì²˜ë¦¬: {stats['total']:,}ê°œ")
    print(f"âœ… ì„±ê³µ: {stats['success']:,}ê°œ ({stats['success']/stats['total']*100:.1f}%)")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed']:,}ê°œ")
    print()

    if stats['by_series']:
        print("ğŸ“š ì‹œë¦¬ì¦ˆë³„:")
        for series, count in sorted(stats['by_series'].items(), key=lambda x: -x[1])[:10]:
            print(f"   {series:15s}: {count:4d}ê°œ")
        print()

    if not dry_run and updated_listings:
        print("ğŸ’¾ ì—…ë°ì´íŠ¸ ì¤‘...")

        update_count = 0
        duplicate_count = 0

        for listing_id, isbn, product_name, series in updated_listings:
            try:
                cursor = conn.cursor()

                cursor.execute("SELECT account_id FROM listings WHERE id = ?", (listing_id,))
                row = cursor.fetchone()
                if not row:
                    continue

                acc_id = row[0]

                # ì¤‘ë³µ ì²´í¬
                cursor.execute("""
                    SELECT COUNT(*) FROM listings
                    WHERE account_id = ? AND isbn = ? AND id != ?
                """, (acc_id, isbn, listing_id))

                if cursor.fetchone()[0] > 0:
                    duplicate_count += 1
                    continue

                cursor.execute("UPDATE listings SET isbn = ? WHERE id = ?", (isbn, listing_id))
                update_count += 1

                if update_count % 100 == 0:
                    conn.commit()
                    print(f"   ì²´í¬í¬ì¸íŠ¸: {update_count:,}ê°œ")

            except Exception as e:
                continue

        conn.commit()
        print(f"âœ… ì™„ë£Œ: {update_count:,}ê°œ")
        if duplicate_count > 0:
            print(f"âš ï¸  ì¤‘ë³µ: {duplicate_count:,}ê°œ")
    else:
        print("âš ï¸  DRY RUN")

    conn.close()

    print()
    print(f"ì¢…ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ìš¸íŠ¸ë¼ ë§¤ì¹­')
    parser.add_argument('--dry-run', action='store_true')
    parser.add_argument('--limit', type=int)
    parser.add_argument('--db', type=str, default='coupang_auto_backup.db')
    parser.add_argument('--account', type=int)

    args = parser.parse_args()

    try:
        stats = fill_isbn_ultra_matching(
            dry_run=args.dry_run,
            limit=args.limit,
            db_path=args.db,
            account_id=args.account
        )

        print()
        print(f"ğŸ“Š ì„±ê³µë¥ : {stats['success']/stats['total']*100:.1f}%")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
